{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8002 session6 EX.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJlzeWre3jtv",
        "outputId": "3112864b-cf84-4f68-fb76-182ca5923178"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Dropout\r\n",
        "from sklearn.metrics import classification_report, confusion_matrix\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import numpy\r\n",
        "from sklearn import linear_model\r\n",
        "from sklearn import preprocessing\r\n",
        "from sklearn import tree\r\n",
        "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\r\n",
        "import pandas as pd\r\n",
        "import csv\r\n",
        "\r\n",
        "\r\n",
        "Y_position = 3\r\n",
        "\r\n",
        "# fix random seed for reproducibility\r\n",
        "numpy.random.seed(7)\r\n",
        "# load pima indians dataset\r\n",
        "dataset = pd.read_csv(\"/content/sample_data/Alternative Property Price 1(Edited).csv\")\r\n",
        "# split into input (X) and output (Y) variables\r\n",
        "\r\n",
        "df = dataset\r\n",
        "print(df)\r\n",
        "\t# summary statistics\r\n",
        "print(df.describe())\r\n",
        "\r\n",
        "corr=df.corr(method ='pearson')\r\n",
        "print(corr)\r\n",
        "corr.to_csv('corr.csv')\r\n",
        "\r\n",
        "X = dataset.iloc[:,0:Y_position]\r\n",
        "Y = dataset.iloc[:,Y_position]\r\n",
        "# create model\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.40, random_state=2020)\r\n",
        "\r\n",
        "#scaling to around -2 to 2 (Z)\r\n",
        "scaler = preprocessing.StandardScaler().fit(X_train)\r\n",
        "scaled_X_train = scaler.transform(X_train)\r\n",
        "scaled_X_test = scaler.transform(X_test)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# Model 7 Naive Nayesian\r\n",
        "# class sklearn.naive_bayes.GaussianNB(*, priors=None, var_smoothing=1e-09)\r\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\r\n",
        "\r\n",
        "gnb = GaussianNB()\r\n",
        "train_and_predict_using_model(\"Naive Bayes\", gnb)\r\n",
        "\r\n",
        "\r\n",
        "# Model 7 Naive Nayesian\r\n",
        "# class sklearn.naive_bayes.GaussianNB(*, priors=None, var_smoothing=1e-09)\r\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\r\n",
        "\r\n",
        "print(\"var_smoothing=0.05\")\r\n",
        "gnb = GaussianNB(var_smoothing=0.05)\r\n",
        "train_and_predict_using_model(\"Naive Bayes\", gnb)\r\n",
        "\r\n",
        "\r\n",
        "print(\"var_smoothing=0.1\")\r\n",
        "gnb = GaussianNB(priors=None,var_smoothing=0.1)\r\n",
        "train_and_predict_using_model(\"Naive Bayes\", gnb)\r\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     1  0  0.1  0.2\n",
            "0    0  1    0    0\n",
            "1    0  0    1    0\n",
            "2    1  0    0    0\n",
            "3    0  1    0    0\n",
            "4    0  0    1    0\n",
            "..  .. ..  ...  ...\n",
            "195  0  1    0    1\n",
            "196  0  0    1    1\n",
            "197  1  0    0    0\n",
            "198  0  1    0    1\n",
            "199  0  0    1    1\n",
            "\n",
            "[200 rows x 4 columns]\n",
            "                1           0         0.1        0.2\n",
            "count  200.000000  200.000000  200.000000  200.00000\n",
            "mean     0.330000    0.335000    0.335000    0.50500\n",
            "std      0.471393    0.473175    0.473175    0.50123\n",
            "min      0.000000    0.000000    0.000000    0.00000\n",
            "25%      0.000000    0.000000    0.000000    0.00000\n",
            "50%      0.000000    0.000000    0.000000    1.00000\n",
            "75%      1.000000    1.000000    1.000000    1.00000\n",
            "max      1.000000    1.000000    1.000000    1.00000\n",
            "            1         0       0.1       0.2\n",
            "1    1.000000 -0.498117 -0.498117 -0.326039\n",
            "0   -0.498117  1.000000 -0.503759  0.151812\n",
            "0.1 -0.498117 -0.503759  1.000000  0.172999\n",
            "0.2 -0.326039  0.151812  0.172999  1.000000\n",
            "Naive Bayes\n",
            "================================\n",
            "Training confusion matrix: \n",
            "[[31 34]\n",
            " [ 9 46]]\n",
            "TrainSet: Accurarcy 64.17%\n",
            "================================\n",
            "[[17 17]\n",
            " [ 9 37]]\n",
            "Testset: Accurarcy 67.50%\n",
            "================================\n",
            "var_smoothing=0.05\n",
            "Naive Bayes\n",
            "================================\n",
            "Training confusion matrix: \n",
            "[[31 34]\n",
            " [ 9 46]]\n",
            "TrainSet: Accurarcy 64.17%\n",
            "================================\n",
            "[[17 17]\n",
            " [ 9 37]]\n",
            "Testset: Accurarcy 67.50%\n",
            "================================\n",
            "var_smoothing=0.1\n",
            "Naive Bayes\n",
            "================================\n",
            "Training confusion matrix: \n",
            "[[31 34]\n",
            " [ 9 46]]\n",
            "TrainSet: Accurarcy 64.17%\n",
            "================================\n",
            "[[17 17]\n",
            " [ 9 37]]\n",
            "Testset: Accurarcy 67.50%\n",
            "================================\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
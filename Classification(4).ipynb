{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6-final"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKC8DUksnGeq"
      },
      "source": [
        "# Example code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ce1il03S6_Te",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e16b57f-0dfa-4aec-b768-67681a17e507"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy\n",
        "from sklearn import linear_model\n",
        "from sklearn import preprocessing\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "\n",
        "Y_position = 4\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"/content/Financial Ratio Edited 2.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "\n",
        "df = pd.DataFrame(dataset)\n",
        "print(df)\n",
        "\t# summary statistics\n",
        "print(df.describe())\n",
        "\n",
        "X = dataset[:,0:Y_position]\n",
        "Y = dataset[:,Y_position]\n",
        "# create model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.40, random_state=2020)\n",
        "\n",
        "#scaling to around -2 to 2 (Z)\n",
        "scaler = preprocessing.StandardScaler().fit(X_train)\n",
        "scaled_X_train = scaler.transform(X_train)\n",
        "scaled_X_test = scaler.transform(X_test)\n",
        "\n",
        "#Model 1 : linear regression\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "#class sklearn.linear_model.LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, \n",
        "#intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', \n",
        "#verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
        "\n",
        "linear_classifier = linear_model.LogisticRegression(random_state=123)\n",
        "linear_classifier.fit(scaled_X_train, y_train)\n",
        "y_pred_train1 = linear_classifier.predict(scaled_X_train)\n",
        "cm1_train = confusion_matrix(y_train,y_pred_train1)\n",
        "print(\"Regression\")\n",
        "print(\"================================\")\n",
        "print(cm1_train)\n",
        "acc_train1 = (cm1_train[0,0] + cm1_train[1,1]) / sum(sum(cm1_train))\n",
        "print(\"Regression TrainSet: Accurarcy %.2f%%\" % (acc_train1*100))\n",
        "print(\"================================\")\n",
        "y_pred1 = linear_classifier.predict(scaled_X_test)\n",
        "cm1 = confusion_matrix(y_test,y_pred1)\n",
        "print(cm1)\n",
        "acc1 = (cm1[0,0] + cm1[1,1]) / sum(sum(cm1))\n",
        "print(\"Regression Testset: Accurarcy %.2f%%\" % (acc1*100))\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "\n",
        "\n",
        "#Model 2: decision tree\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
        "#class sklearn.tree.DecisionTreeClassifier(*, criterion='gini', splitter='best', max_depth=None, min_samples_split=2, \n",
        "#min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, \n",
        "#min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort='deprecated', ccp_alpha=0.0)\n",
        "\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "clf = clf.fit(scaled_X_train, y_train)\n",
        "y_pred_train2 = clf.predict(scaled_X_train)\n",
        "cm2_train = confusion_matrix(y_train,y_pred_train2)\n",
        "print(\"Decision Tree\")\n",
        "print(\"================================\")\n",
        "print(cm2_train)\n",
        "acc_train2 = (cm2_train[0,0] + cm2_train[1,1]) / sum(sum(cm2_train))\n",
        "print(\"Decsion Tree TrainSet: Accurarcy %.2f%%\" % (acc_train2*100))\n",
        "print(\"================================\")\n",
        "y_pred2 = clf.predict(scaled_X_test)\n",
        "cm2 = confusion_matrix(y_test,y_pred2)\n",
        "acc2 = (cm2[0,0] + cm2[1,1]) / sum(sum(cm2))\n",
        "print(cm2)\n",
        "print(\"Decision Tree Testset: Accurarcy %.2f%%\" % (acc2*100))\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "\n",
        "\n",
        "#Model 3 random forest\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "#class sklearn.ensemble.RandomForestClassifier(n_estimators=100, *, criterion='gini', max_depth=None, \n",
        "#min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', \n",
        "#max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, \n",
        "#n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)[source]\n",
        "\n",
        "model3 = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0)\n",
        "model3.fit(scaled_X_train, y_train)\n",
        "y_predicted3 = model3.predict(scaled_X_test)\n",
        "\n",
        "y_pred_train3 = model3.predict(scaled_X_train)\n",
        "cm3_train = confusion_matrix(y_train,y_pred_train3)\n",
        "print(\"Random Forest\")\n",
        "print(\"================================\")\n",
        "print(cm3_train)\n",
        "acc_train3 = (cm3_train[0,0] + cm3_train[1,1]) / sum(sum(cm3_train))\n",
        "print(\"Random Forest TrainSet: Accurarcy %.2f%%\" % (acc_train3*100))\n",
        "print(\"================================\")\n",
        "y_pred3 = model3.predict(scaled_X_test)\n",
        "cm_test3 = confusion_matrix(y_test,y_pred3)\n",
        "print(cm_test3)\n",
        "acc_test3 = (cm_test3[0,0] + cm_test3[1,1]) / sum(sum(cm_test3))\n",
        "print(\"Random Forest Testset: Accurarcy %.2f%%\" % (acc_test3*100))\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "\n",
        "#Model 4: XGBoost\n",
        "\n",
        "print(\"Xgboost\")\n",
        "print(\"================================\")\n",
        "#class sklearn.ensemble.GradientBoostingClassifier(*, loss='deviance', learning_rate=0.1, n_estimators=100, \n",
        "#subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
        "#max_depth=3, min_impurity_decrease=0.0, min_impurity_split=None, init=None, random_state=None, max_features=None, \n",
        "#verbose=0, max_leaf_nodes=None, warm_start=False, presort='deprecated', validation_fraction=0.1, \n",
        "#n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)[source]\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
        "\n",
        "model4 = GradientBoostingClassifier(random_state=0)\n",
        "model4.fit(scaled_X_train, y_train)\n",
        "y_pred_train4 = model4.predict(scaled_X_train)\n",
        "cm4_train = confusion_matrix(y_train,y_pred_train4)\n",
        "print(cm4_train)\n",
        "acc_train4 = (cm4_train[0,0] + cm4_train[1,1]) / sum(sum(cm4_train))\n",
        "print(\"Xgboost TrainSet: Accurarcy %.2f%%\" % (acc_train4*100))\n",
        "predictions = model4.predict(scaled_X_test)\n",
        "y_pred4 = (predictions > 0.5)\n",
        "y_pred4 =y_pred4*1 #convert to 0,1 instead of True False\n",
        "cm4 = confusion_matrix(y_test, y_pred4)\n",
        "print(\"==================================\")\n",
        "print(\"Xgboost on testset confusion matrix\")\n",
        "print(cm4)\n",
        "acc4 = (cm4[0,0] + cm4[1,1]) / sum(sum(cm4))\n",
        "print(\"Xgboost on TestSet: Accuracy %.2f%%\" % (acc4*100))\n",
        "print(\"==================================\")\n",
        "\n",
        "#Model 5: neural network\n",
        "#https://www.tensorflow.org/guide/keras/train_and_evaluate\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=Y_position, activation='relu'))\n",
        "#model.add(Dense(10, activation='relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# Compile mode\n",
        "# https://www.tensorflow.org/guide/keras/train_and_evaluate\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=5, verbose=0)\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X_train, y_train)\n",
        "#print(scores)\n",
        "print(\"Neural Network Trainset: \\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "predictions5 = model.predict(X_test)\n",
        "#print(predictions)\n",
        "#print('predictions shape:', predictions.shape)\n",
        "\n",
        "y_pred5 = (predictions5 > 0.5)\n",
        "y_pred5 = y_pred5*1 #convert to 0,1 instead of True False\n",
        "cm5 = confusion_matrix(y_test, y_pred5)\n",
        "print(\"==================================\")\n",
        "print(\"==================================\")\n",
        "print(\"Neural Network on testset confusion matrix\")\n",
        "print(cm5)\n",
        "\n",
        "## Get accurary from Confusion matrix\n",
        "## Position 0,0 and 1,1 are the correct predictions \n",
        "acc5 = (cm5[0,0] + cm5[1,1]) / sum(sum(cm5))\n",
        "print(\"Neural Network on TestSet: Accuracy %.2f%%\" % (acc5*100))\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           0      1       2      3    4\n",
            "0     1.0000  0.310  0.1974  0.124  0.0\n",
            "1     0.4847  0.453  0.2908  0.105  1.0\n",
            "2     0.6173  0.456  0.3273  0.297  0.0\n",
            "3     0.5887  0.638  0.4819  0.465  0.0\n",
            "4     1.0000  0.402  0.3790  0.293  0.0\n",
            "...      ...    ...     ...    ...  ...\n",
            "1016  0.5944  1.772  1.5356  1.344  0.0\n",
            "1017  0.6813  0.610  0.2831  0.132  1.0\n",
            "1018  0.2112  0.130  0.0737  0.052  0.0\n",
            "1019  0.3060  0.292  0.1899  0.189  1.0\n",
            "1020  0.1504  0.148  0.1159  0.085  0.0\n",
            "\n",
            "[1021 rows x 5 columns]\n",
            "                 0            1            2            3            4\n",
            "count  1021.000000  1021.000000  1021.000000  1021.000000  1021.000000\n",
            "mean      0.513275    -0.173637     0.220749    -0.320973     0.499510\n",
            "std       0.274916    14.960709     0.236005    15.033043     0.500245\n",
            "min      -0.066700  -477.663000    -0.006100  -480.171000     0.000000\n",
            "25%       0.302500     0.126000     0.088900     0.049000     0.000000\n",
            "50%       0.450100     0.225000     0.162800     0.096000     0.000000\n",
            "75%       0.706900     0.397000     0.291600     0.201000     1.000000\n",
            "max       1.000000     5.300000     5.175200     3.143000     1.000000\n",
            "Regression\n",
            "================================\n",
            "[[187 111]\n",
            " [114 200]]\n",
            "Regression TrainSet: Accurarcy 63.24%\n",
            "================================\n",
            "[[115  98]\n",
            " [ 76 120]]\n",
            "Regression Testset: Accurarcy 57.46%\n",
            "================================\n",
            "================================\n",
            "================================\n",
            "Decision Tree\n",
            "================================\n",
            "[[298   0]\n",
            " [  0 314]]\n",
            "Decsion Tree TrainSet: Accurarcy 100.00%\n",
            "================================\n",
            "[[122  91]\n",
            " [ 79 117]]\n",
            "Decision Tree Testset: Accurarcy 58.44%\n",
            "================================\n",
            "================================\n",
            "================================\n",
            "Random Forest\n",
            "================================\n",
            "[[187 111]\n",
            " [ 80 234]]\n",
            "Random Forest TrainSet: Accurarcy 68.79%\n",
            "================================\n",
            "[[114  99]\n",
            " [ 64 132]]\n",
            "Random Forest Testset: Accurarcy 60.15%\n",
            "================================\n",
            "================================\n",
            "================================\n",
            "Xgboost\n",
            "================================\n",
            "[[255  43]\n",
            " [ 28 286]]\n",
            "Xgboost TrainSet: Accurarcy 88.40%\n",
            "==================================\n",
            "Xgboost on testset confusion matrix\n",
            "[[126  87]\n",
            " [ 59 137]]\n",
            "Xgboost on TestSet: Accuracy 64.30%\n",
            "==================================\n",
            "20/20 [==============================] - 0s 1ms/step - loss: 0.6669 - accuracy: 0.6650\n",
            "Neural Network Trainset: \n",
            "accuracy: 66.50%\n",
            "==================================\n",
            "==================================\n",
            "Neural Network on testset confusion matrix\n",
            "[[ 73 140]\n",
            " [ 28 168]]\n",
            "Neural Network on TestSet: Accuracy 58.92%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLXptszenQpc"
      },
      "source": [
        "## Model helper function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDNrvC23nSDS"
      },
      "source": [
        "def train_and_predict_using_model(model_name= \"\",model=None):\n",
        "    model.fit(scaled_X_train, y_train)\n",
        "    y_predicted = model3.predict(scaled_X_test)\n",
        "    y_pred_train = model.predict(scaled_X_train)\n",
        "    cm_train = confusion_matrix(y_train,y_pred_train)\n",
        "    print(model_name)\n",
        "    print(\"================================\")\n",
        "    print(\"Training confusion matrix: \")\n",
        "    print(cm_train)\n",
        "    acc_train = (cm_train[0,0] + cm_train[1,1]) / sum(sum(cm_train))\n",
        "    print(\"TrainSet: Accurarcy %.2f%%\" % (acc_train*100))\n",
        "    print(\"================================\")\n",
        "    y_pred = model.predict(scaled_X_test)\n",
        "    cm_test = confusion_matrix(y_test,y_pred)\n",
        "    print(cm_test)\n",
        "    acc_test = (cm_test[0,0] + cm_test[1,1]) / sum(sum(cm_test))\n",
        "    print(\"Testset: Accurarcy %.2f%%\" % (acc_test*100))\n",
        "    print(\"================================\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nSZP7j1dIBJ"
      },
      "source": [
        "## Feature importance\n",
        "\n",
        "### Feature importances with forests of trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "whZbWt0hdIBK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f359b67-1190-49ad-9501-411322d7442b"
      },
      "source": [
        "RF = model3\n",
        "importances = RF.feature_importances_\n",
        "std = numpy.std([tree.feature_importances_ for tree in RF.estimators_],\n",
        "             axis=0)\n",
        "indices = numpy.argsort(importances)[::-1]\n",
        "\n",
        "# Print the feature ranking\n",
        "print(\"Feature ranking:\")\n",
        "\n",
        "for f in range(X.shape[1]):\n",
        "    print(\"%d. feature (Column index) %s (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature ranking:\n",
            "1. feature (Column index) 0 (0.365499)\n",
            "2. feature (Column index) 3 (0.363115)\n",
            "3. feature (Column index) 2 (0.160760)\n",
            "4. feature (Column index) 1 (0.110626)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuDxnhWGdIBh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "5668102c-7837-4052-a128-bd6a3802cffd"
      },
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "boxplot = pd.DataFrame(dataset).boxplot()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXFywaNXvGxt"
      },
      "source": [
        "## Remove outlier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vDI9ZQJvDq2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d09a1b14-d9d9-458c-9f74-7afecc377e1c"
      },
      "source": [
        "df = pd.DataFrame(dataset)\n",
        "quantile = df[4].quantile(0.99)\n",
        "df1 = df[df[4] < quantile]\n",
        "df.shape, df1.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1021, 5), (511, 5))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGgSwffuvIRV"
      },
      "source": [
        "df1 = df1.dropna()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0oHOT1nvTkH"
      },
      "source": [
        "## Use top 3 features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRvAbgUivSsX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28397b47-09b8-4112-bf52-897ed42abb1c"
      },
      "source": [
        "Y_position = 4\n",
        "TOP_N_FEATURE = 3\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"/content/Financial Ratio Edited 2.csv\", delimiter=\",\")\n",
        "\n",
        "df = pd.DataFrame(dataset)\n",
        "\n",
        "indices_top3 = indices[:TOP_N_FEATURE]\n",
        "print(indices_top3)\n",
        "\n",
        "X = dataset[:,indices_top3]\n",
        "Y = dataset[:,Y_position]\n",
        "# create model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=2020)\n",
        "\n",
        "\n",
        "#scaling to around -2 to 2 (Z)\n",
        "scaler = preprocessing.StandardScaler().fit(X_train)\n",
        "scaled_X_train = scaler.transform(X_train)\n",
        "scaled_X_test = scaler.transform(X_test)\n",
        "\n",
        "#Model 1 : linear regression\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "#class sklearn.linear_model.LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, \n",
        "#intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', \n",
        "#verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
        "\n",
        "linear_classifier = linear_model.LogisticRegression(random_state=123)\n",
        "linear_classifier.fit(scaled_X_train, y_train)\n",
        "y_pred_train1 = linear_classifier.predict(scaled_X_train)\n",
        "cm1_train = confusion_matrix(y_train,y_pred_train1)\n",
        "print(\"Regression\")\n",
        "print(\"================================\")\n",
        "print(cm1_train)\n",
        "acc_train1 = (cm1_train[0,0] + cm1_train[1,1]) / sum(sum(cm1_train))\n",
        "print(\"Regression TrainSet: Accurarcy %.2f%%\" % (acc_train1*100))\n",
        "print(\"================================\")\n",
        "y_pred1 = linear_classifier.predict(scaled_X_test)\n",
        "cm1 = confusion_matrix(y_test,y_pred1)\n",
        "print(cm1)\n",
        "acc1 = (cm1[0,0] + cm1[1,1]) / sum(sum(cm1))\n",
        "print(\"Regression Testset: Accurarcy %.2f%%\" % (acc1*100))\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "\n",
        "\n",
        "#Model 2: decision tree\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
        "#class sklearn.tree.DecisionTreeClassifier(*, criterion='gini', splitter='best', max_depth=None, min_samples_split=2, \n",
        "#min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, \n",
        "#min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort='deprecated', ccp_alpha=0.0)\n",
        "\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "clf = clf.fit(scaled_X_train, y_train)\n",
        "y_pred_train2 = clf.predict(scaled_X_train)\n",
        "cm2_train = confusion_matrix(y_train,y_pred_train2)\n",
        "print(\"Decision Tree\")\n",
        "print(\"================================\")\n",
        "print(cm2_train)\n",
        "acc_train2 = (cm2_train[0,0] + cm2_train[1,1]) / sum(sum(cm2_train))\n",
        "print(\"Decsion Tree TrainSet: Accurarcy %.2f%%\" % (acc_train2*100))\n",
        "print(\"================================\")\n",
        "y_pred2 = clf.predict(scaled_X_test)\n",
        "cm2 = confusion_matrix(y_test,y_pred2)\n",
        "acc2 = (cm2[0,0] + cm2[1,1]) / sum(sum(cm2))\n",
        "print(cm2)\n",
        "print(\"Decision Tree Testset: Accurarcy %.2f%%\" % (acc2*100))\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "\n",
        "\n",
        "#Model 3 random forest\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "#class sklearn.ensemble.RandomForestClassifier(n_estimators=100, *, criterion='gini', max_depth=None, \n",
        "#min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', \n",
        "#max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, \n",
        "#n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)[source]\n",
        "\n",
        "model3 = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0)\n",
        "model3.fit(scaled_X_train, y_train)\n",
        "y_predicted3 = model3.predict(scaled_X_test)\n",
        "\n",
        "y_pred_train3 = model3.predict(scaled_X_train)\n",
        "cm3_train = confusion_matrix(y_train,y_pred_train3)\n",
        "print(\"Random Forest\")\n",
        "print(\"================================\")\n",
        "print(cm3_train)\n",
        "acc_train3 = (cm3_train[0,0] + cm3_train[1,1]) / sum(sum(cm3_train))\n",
        "print(\"Random Forest TrainSet: Accurarcy %.2f%%\" % (acc_train3*100))\n",
        "print(\"================================\")\n",
        "y_pred3 = model3.predict(scaled_X_test)\n",
        "cm_test3 = confusion_matrix(y_test,y_pred3)\n",
        "print(cm_test3)\n",
        "acc_test3 = (cm_test3[0,0] + cm_test3[1,1]) / sum(sum(cm_test3))\n",
        "print(\"Random Forest Testset: Accurarcy %.2f%%\" % (acc_test3*100))\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "\n",
        "#Model 4: XGBoost\n",
        "\n",
        "print(\"Xgboost\")\n",
        "print(\"================================\")\n",
        "#class sklearn.ensemble.GradientBoostingClassifier(*, loss='deviance', learning_rate=0.1, n_estimators=100, \n",
        "#subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
        "#max_depth=3, min_impurity_decrease=0.0, min_impurity_split=None, init=None, random_state=None, max_features=None, \n",
        "#verbose=0, max_leaf_nodes=None, warm_start=False, presort='deprecated', validation_fraction=0.1, \n",
        "#n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)[source]\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
        "\n",
        "model4 = GradientBoostingClassifier(random_state=0)\n",
        "model4.fit(scaled_X_train, y_train)\n",
        "y_pred_train4 = model4.predict(scaled_X_train)\n",
        "cm4_train = confusion_matrix(y_train,y_pred_train4)\n",
        "print(cm4_train)\n",
        "acc_train4 = (cm4_train[0,0] + cm4_train[1,1]) / sum(sum(cm4_train))\n",
        "print(\"Xgboost TrainSet: Accurarcy %.2f%%\" % (acc_train4*100))\n",
        "predictions = model4.predict(scaled_X_test)\n",
        "y_pred4 = (predictions > 0.5)\n",
        "y_pred4 =y_pred4*1 #convert to 0,1 instead of True False\n",
        "cm4 = confusion_matrix(y_test, y_pred4)\n",
        "print(\"==================================\")\n",
        "print(\"Xgboost on testset confusion matrix\")\n",
        "print(cm4)\n",
        "acc4 = (cm4[0,0] + cm4[1,1]) / sum(sum(cm4))\n",
        "print(\"Xgboost on TestSet: Accuracy %.2f%%\" % (acc4*100))\n",
        "print(\"==================================\")\n",
        "\n",
        "#Model 5: neural network\n",
        "#https://www.tensorflow.org/guide/keras/train_and_evaluate\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=TOP_N_FEATURE, activation='relu'))\n",
        "#model.add(Dense(10, activation='relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# Compile mode\n",
        "# https://www.tensorflow.org/guide/keras/train_and_evaluate\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=5, verbose=0)\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X_train, y_train)\n",
        "#print(scores)\n",
        "print(\"Neural Network Trainset: \\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "predictions5 = model.predict(X_test)\n",
        "#print(predictions)\n",
        "#print('predictions shape:', predictions.shape)\n",
        "\n",
        "y_pred5 = (predictions5 > 0.5)\n",
        "y_pred5 = y_pred5*1 #convert to 0,1 instead of True False\n",
        "cm5 = confusion_matrix(y_test, y_pred5)\n",
        "print(\"==================================\")\n",
        "print(\"==================================\")\n",
        "print(\"Neural Network on testset confusion matrix\")\n",
        "print(cm5)\n",
        "\n",
        "## Get accurary from Confusion matrix\n",
        "## Position 0,0 and 1,1 are the correct predictions \n",
        "acc5 = (cm5[0,0] + cm5[1,1]) / sum(sum(cm5))\n",
        "print(\"Neural Network on TestSet: Accuracy %.2f%%\" % (acc5*100))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 3 2]\n",
            "Regression\n",
            "================================\n",
            "[[148 254]\n",
            " [101 313]]\n",
            "Regression TrainSet: Accurarcy 56.50%\n",
            "================================\n",
            "[[37 72]\n",
            " [25 71]]\n",
            "Regression Testset: Accurarcy 52.68%\n",
            "================================\n",
            "================================\n",
            "================================\n",
            "Decision Tree\n",
            "================================\n",
            "[[402   0]\n",
            " [  0 414]]\n",
            "Decsion Tree TrainSet: Accurarcy 100.00%\n",
            "================================\n",
            "[[66 43]\n",
            " [47 49]]\n",
            "Decision Tree Testset: Accurarcy 56.10%\n",
            "================================\n",
            "================================\n",
            "================================\n",
            "Random Forest\n",
            "================================\n",
            "[[160 242]\n",
            " [ 73 341]]\n",
            "Random Forest TrainSet: Accurarcy 61.40%\n",
            "================================\n",
            "[[46 63]\n",
            " [22 74]]\n",
            "Random Forest Testset: Accurarcy 58.54%\n",
            "================================\n",
            "================================\n",
            "================================\n",
            "Xgboost\n",
            "================================\n",
            "[[323  79]\n",
            " [ 49 365]]\n",
            "Xgboost TrainSet: Accurarcy 84.31%\n",
            "==================================\n",
            "Xgboost on testset confusion matrix\n",
            "[[63 46]\n",
            " [35 61]]\n",
            "Xgboost on TestSet: Accuracy 60.49%\n",
            "==================================\n",
            "26/26 [==============================] - 0s 912us/step - loss: 0.7773 - accuracy: 0.6176\n",
            "Neural Network Trainset: \n",
            "accuracy: 61.76%\n",
            "==================================\n",
            "==================================\n",
            "Neural Network on testset confusion matrix\n",
            "[[41 68]\n",
            " [24 72]]\n",
            "Neural Network on TestSet: Accuracy 55.12%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAgMlQOWhJjA"
      },
      "source": [
        ""
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEGm4HurdgXA"
      },
      "source": [
        "# Other models and how to configure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8F3EhgupiKda"
      },
      "source": [
        "## SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyVH_vlnh_HQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53f92eac-395f-492b-bdd0-1b99f9ae083f"
      },
      "source": [
        "from sklearn import svm\n",
        "\n",
        "clf = svm.SVC()\n",
        "train_and_predict_using_model(\"SVM (Classifier)\", clf)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM (Classifier)\n",
            "================================\n",
            "Training confusion matrix: \n",
            "[[240 162]\n",
            " [133 281]]\n",
            "TrainSet: Accurarcy 63.85%\n",
            "================================\n",
            "[[68 41]\n",
            " [34 62]]\n",
            "Testset: Accurarcy 63.41%\n",
            "================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IY2MhXmiuF3"
      },
      "source": [
        "### Important hyper parameters:\n",
        "- kernel\n",
        "    - rbf\n",
        "    - polynomial\n",
        "    - sigmoid\n",
        "\n",
        "- class weight\n",
        "    - for unbalanced dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGfeFhrcitKP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed2acd3d-7680-46f6-9004-6781f3128cd2"
      },
      "source": [
        "rbf_svc = svm.SVC(kernel='rbf')\n",
        "train_and_predict_using_model(\"SVM (RBF kernel)\", rbf_svc)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM (RBF kernel)\n",
            "================================\n",
            "Training confusion matrix: \n",
            "[[240 162]\n",
            " [133 281]]\n",
            "TrainSet: Accurarcy 63.85%\n",
            "================================\n",
            "[[68 41]\n",
            " [34 62]]\n",
            "Testset: Accurarcy 63.41%\n",
            "================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaHNNSaQiW5B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58671775-68fc-472f-e7ab-bb674077fb42"
      },
      "source": [
        "pol_svc = svm.SVC(kernel='poly')\n",
        "train_and_predict_using_model(\"SVM (polynomial kernel)\", pol_svc)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM (polynomial kernel)\n",
            "================================\n",
            "Training confusion matrix: \n",
            "[[ 80 322]\n",
            " [ 22 392]]\n",
            "TrainSet: Accurarcy 57.84%\n",
            "================================\n",
            "[[26 83]\n",
            " [ 4 92]]\n",
            "Testset: Accurarcy 57.56%\n",
            "================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxKK5-FZjKGN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7354421-9923-4cb0-96ad-56be62c2f0fd"
      },
      "source": [
        "sig_svc = svm.SVC(kernel='sigmoid')\n",
        "train_and_predict_using_model(\"SVM (sigmoid kernel)\", sig_svc)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM (sigmoid kernel)\n",
            "================================\n",
            "Training confusion matrix: \n",
            "[[183 219]\n",
            " [218 196]]\n",
            "TrainSet: Accurarcy 46.45%\n",
            "================================\n",
            "[[51 58]\n",
            " [49 47]]\n",
            "Testset: Accurarcy 47.80%\n",
            "================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZ0nBLjcjeo6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b75b4ea1-905d-4312-db74-488c7966df87"
      },
      "source": [
        "# fit the model and get the separating hyperplane using weighted classes\n",
        "wclf = svm.SVC(kernel='linear', class_weight={1:2})\n",
        "train_and_predict_using_model('SVM uneven class weight', wclf)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM uneven class weight\n",
            "================================\n",
            "Training confusion matrix: \n",
            "[[  1 401]\n",
            " [  0 414]]\n",
            "TrainSet: Accurarcy 50.86%\n",
            "================================\n",
            "[[  0 109]\n",
            " [  0  96]]\n",
            "Testset: Accurarcy 46.83%\n",
            "================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKJBjSe0ke7Y"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qphxloNj1D9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c727ca53-e7b5-4cd4-b428-e2593a23e97a"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# maximum likelihood\n",
        "\n",
        "gnb = GaussianNB()\n",
        "train_and_predict_using_model(\"Naive Bayes\", gnb)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes\n",
            "================================\n",
            "Training confusion matrix: \n",
            "[[  7 395]\n",
            " [  1 413]]\n",
            "TrainSet: Accurarcy 51.47%\n",
            "================================\n",
            "[[  1 108]\n",
            " [  0  96]]\n",
            "Testset: Accurarcy 47.32%\n",
            "================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUCsq6QvlDNQ"
      },
      "source": [
        "### Important hyper parameters:\n",
        "\n",
        "- Priors\n",
        "    - estimator will calculate for you. Not recommended to change. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URo0PGMilk97"
      },
      "source": [
        ""
      ],
      "execution_count": 35,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification(6).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6-final"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ce1il03S6_Te",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9a828f2-d648-4e2a-ec42-9600ca7cc37f"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy\n",
        "from sklearn import linear_model\n",
        "from sklearn import preprocessing\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "\n",
        "Y_position = 4\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "# load pima indians dataset\n",
        "dataset = pd.read_csv(\"/content/sample_data/Bonds bankruptcy Data (Edited & Balance).csv\")\n",
        "# split into input (X) and output (Y) variables\n",
        "\n",
        "df = dataset\n",
        "print(df)\n",
        "\t# summary statistics\n",
        "print(df.describe())\n",
        "\n",
        "corr=df.corr(method ='pearson')\n",
        "print(corr)\n",
        "corr.to_csv('corr.csv')\n",
        "\n",
        "X = dataset.iloc[:,0:Y_position]\n",
        "Y = dataset.iloc[:,Y_position]\n",
        "# create model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.40, random_state=2020)\n",
        "\n",
        "#scaling to around -2 to 2 (Z)\n",
        "scaler = preprocessing.StandardScaler().fit(X_train)\n",
        "scaled_X_train = scaler.transform(X_train)\n",
        "scaled_X_test = scaler.transform(X_test)\n",
        "\n",
        "#Model 1 : linear regression\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "#class sklearn.linear_model.LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, \n",
        "#intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', \n",
        "#verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
        "\n",
        "linear_classifier = linear_model.LogisticRegression(random_state=123)\n",
        "linear_classifier.fit(scaled_X_train, y_train)\n",
        "y_pred_train1 = linear_classifier.predict(scaled_X_train)\n",
        "cm1_train = confusion_matrix(y_train,y_pred_train1)\n",
        "print(\"Regression\")\n",
        "print(\"================================\")\n",
        "print(cm1_train)\n",
        "acc_train1 = (cm1_train[0,0] + cm1_train[1,1]) / sum(sum(cm1_train))\n",
        "print(\"Regression TrainSet: Accurarcy %.2f%%\" % (acc_train1*100))\n",
        "print(\"================================\")\n",
        "y_pred1 = linear_classifier.predict(scaled_X_test)\n",
        "cm1 = confusion_matrix(y_test,y_pred1)\n",
        "print(cm1)\n",
        "acc1 = (cm1[0,0] + cm1[1,1]) / sum(sum(cm1))\n",
        "print(\"Regression Testset: Accurarcy %.2f%%\" % (acc1*100))\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "\n",
        "\n",
        "#Model 2: decision tree\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
        "#class sklearn.tree.DecisionTreeClassifier(*, criterion='gini', splitter='best', max_depth=None, min_samples_split=2, \n",
        "#min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, \n",
        "#min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort='deprecated', ccp_alpha=0.0)\n",
        "\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "clf = clf.fit(scaled_X_train, y_train)\n",
        "y_pred_train2 = clf.predict(scaled_X_train)\n",
        "cm2_train = confusion_matrix(y_train,y_pred_train2)\n",
        "print(\"Decision Tree\")\n",
        "print(\"================================\")\n",
        "print(cm2_train)\n",
        "acc_train2 = (cm2_train[0,0] + cm2_train[1,1]) / sum(sum(cm2_train))\n",
        "print(\"Decsion Tree TrainSet: Accurarcy %.2f%%\" % (acc_train2*100))\n",
        "print(\"================================\")\n",
        "y_pred2 = clf.predict(scaled_X_test)\n",
        "cm2 = confusion_matrix(y_test,y_pred2)\n",
        "acc2 = (cm2[0,0] + cm2[1,1]) / sum(sum(cm2))\n",
        "print(cm2)\n",
        "print(\"Decision Tree Testset: Accurarcy %.2f%%\" % (acc2*100))\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "\n",
        "\n",
        "#Model 3 random forest\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "#class sklearn.ensemble.RandomForestClassifier(n_estimators=100, *, criterion='gini', max_depth=None, \n",
        "#min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', \n",
        "#max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, \n",
        "#n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)[source]\n",
        "\n",
        "model3 = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0)\n",
        "model3.fit(scaled_X_train, y_train)\n",
        "y_predicted3 = model3.predict(scaled_X_test)\n",
        "\n",
        "y_pred_train3 = model3.predict(scaled_X_train)\n",
        "cm3_train = confusion_matrix(y_train,y_pred_train3)\n",
        "print(\"Random Forest\")\n",
        "print(\"================================\")\n",
        "print(cm3_train)\n",
        "acc_train3 = (cm3_train[0,0] + cm3_train[1,1]) / sum(sum(cm3_train))\n",
        "print(\"Random Forest TrainSet: Accurarcy %.2f%%\" % (acc_train3*100))\n",
        "print(\"================================\")\n",
        "y_pred3 = model3.predict(scaled_X_test)\n",
        "cm_test3 = confusion_matrix(y_test,y_pred3)\n",
        "print(cm_test3)\n",
        "acc_test3 = (cm_test3[0,0] + cm_test3[1,1]) / sum(sum(cm_test3))\n",
        "print(\"Random Forest Testset: Accurarcy %.2f%%\" % (acc_test3*100))\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "\n",
        "#Model 4: XGBoost\n",
        "\n",
        "print(\"Xgboost\")\n",
        "print(\"================================\")\n",
        "#class sklearn.ensemble.GradientBoostingClassifier(*, loss='deviance', learning_rate=0.1, n_estimators=100, \n",
        "#subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
        "#max_depth=3, min_impurity_decrease=0.0, min_impurity_split=None, init=None, random_state=None, max_features=None, \n",
        "#verbose=0, max_leaf_nodes=None, warm_start=False, presort='deprecated', validation_fraction=0.1, \n",
        "#n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)[source]\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
        "\n",
        "model4 = GradientBoostingClassifier(random_state=0)\n",
        "model4.fit(scaled_X_train, y_train)\n",
        "y_pred_train4 = model4.predict(scaled_X_train)\n",
        "cm4_train = confusion_matrix(y_train,y_pred_train4)\n",
        "print(cm4_train)\n",
        "acc_train4 = (cm4_train[0,0] + cm4_train[1,1]) / sum(sum(cm4_train))\n",
        "print(\"Xgboost TrainSet: Accurarcy %.2f%%\" % (acc_train4*100))\n",
        "predictions = model4.predict(scaled_X_test)\n",
        "y_pred4 = (predictions > 0.5)\n",
        "y_pred4 =y_pred4*1 #convert to 0,1 instead of True False\n",
        "cm4 = confusion_matrix(y_test, y_pred4)\n",
        "print(\"==================================\")\n",
        "print(\"Xgboost on testset confusion matrix\")\n",
        "print(cm4)\n",
        "acc4 = (cm4[0,0] + cm4[1,1]) / sum(sum(cm4))\n",
        "print(\"Xgboost on TestSet: Accuracy %.2f%%\" % (acc4*100))\n",
        "print(\"==================================\")\n",
        "\n",
        "#Model 5: neural network\n",
        "#https://www.tensorflow.org/guide/keras/train_and_evaluate\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=Y_position, activation='relu'))\n",
        "#model.add(Dense(10, activation='relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# Compile mode\n",
        "# https://www.tensorflow.org/guide/keras/train_and_evaluate\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=5, verbose=0)\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X_train, y_train)\n",
        "#print(scores)\n",
        "print(\"Neural Network Trainset: \\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "predictions5 = model.predict(X_test)\n",
        "#print(predictions)\n",
        "#print('predictions shape:', predictions.shape)\n",
        "\n",
        "y_pred5 = (predictions5 > 0.5)\n",
        "y_pred5 = y_pred5*1 #convert to 0,1 instead of True False\n",
        "cm5 = confusion_matrix(y_test, y_pred5)\n",
        "print(\"==================================\")\n",
        "print(\"==================================\")\n",
        "print(\"Neural Network on testset confusion matrix\")\n",
        "print(cm5)\n",
        "\n",
        "## Get accurary from Confusion matrix\n",
        "## Position 0,0 and 1,1 are the correct predictions \n",
        "acc5 = (cm5[0,0] + cm5[1,1]) / sum(sum(cm5))\n",
        "print(\"Neural Network on TestSet: Accuracy %.2f%%\" % (acc5*100))\n",
        "\n",
        "#================== Model 6 SVM and 7 Naive Bayesian\n",
        "\n",
        "\n",
        "def train_and_predict_using_model(model_name= \"\",model=None):\n",
        "    model.fit(scaled_X_train, y_train)\n",
        "    y_predicted = model3.predict(scaled_X_test)\n",
        "    y_pred_train = model.predict(scaled_X_train)\n",
        "    cm_train = confusion_matrix(y_train,y_pred_train)\n",
        "    print(model_name)\n",
        "    print(\"================================\")\n",
        "    print(\"Training confusion matrix: \")\n",
        "    print(cm_train)\n",
        "    acc_train = (cm_train[0,0] + cm_train[1,1]) / sum(sum(cm_train))\n",
        "    print(\"TrainSet: Accurarcy %.2f%%\" % (acc_train*100))\n",
        "    print(\"================================\")\n",
        "    y_pred = model.predict(scaled_X_test)\n",
        "    cm_test = confusion_matrix(y_test,y_pred)\n",
        "    print(cm_test)\n",
        "    acc_test = (cm_test[0,0] + cm_test[1,1]) / sum(sum(cm_test))\n",
        "    print(\"Testset: Accurarcy %.2f%%\" % (acc_test*100))\n",
        "    print(\"================================\")\n",
        "\n",
        "\n",
        "#Model 6 SVM \n",
        "# class sklearn.svm.SVC(*, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, \n",
        "# tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
        "# kernel{‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’}, default=’rbf’\n",
        "\n",
        "from sklearn import svm\n",
        "\n",
        "clf = svm.SVC()\n",
        "train_and_predict_using_model(\"SVM (Classifier)\", clf)\n",
        "\n",
        "clf = svm.SVC(tol=0.0005)\n",
        "train_and_predict_using_model(\"SVM (tol=0.0005)\", clf)\n",
        "\n",
        "clf = svm.SVC(degree=2)\n",
        "train_and_predict_using_model(\"SVM (degree=2)\", clf)\n",
        "\n",
        "\n",
        "rbf_svc = svm.SVC(kernel='rbf')\n",
        "train_and_predict_using_model(\"SVM (RBF kernel)\", rbf_svc)\n",
        "\n",
        "rbf_svc = svm.SVC(kernel='sigmoid')\n",
        "train_and_predict_using_model(\"SVM (sigmoid)\", rbf_svc)\n",
        "\n",
        "rbf_svc = svm.SVC(kernel='linear')\n",
        "train_and_predict_using_model(\"SVM (Linear)\", rbf_svc)\n",
        "\n",
        "\n",
        "# fit the model and get the separating hyperplane using weighted classes\n",
        "wclf = svm.SVC(kernel='linear', class_weight={1:2})\n",
        "train_and_predict_using_model('SVM uneven class weight', wclf)\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Model 7 Naive Nayesian\n",
        "# class sklearn.naive_bayes.GaussianNB(*, priors=None, var_smoothing=1e-09)\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\n",
        "\n",
        "gnb = GaussianNB()\n",
        "train_and_predict_using_model(\"Naive Bayes\", gnb)\n",
        "\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        Attr1     Attr2     Attr3     Attr4  class\n",
            "0   -0.086208 -0.041815 -0.007974 -0.082415      1\n",
            "1   -0.034655  0.013788  0.120081 -0.110792      1\n",
            "2   -0.454512  0.009128 -1.330367 -0.313777      1\n",
            "3   -1.856905  0.579749 -1.102942 -0.279015      1\n",
            "4   -0.055054  0.102515 -0.435038 -0.187300      1\n",
            "..        ...       ...       ...       ...    ...\n",
            "594 -0.100140  0.063698 -0.062937 -0.097755      0\n",
            "595 -0.022752  0.025541 -0.577176 -0.197877      0\n",
            "596 -0.164790 -0.023233 -0.374772 -0.172018      0\n",
            "597  0.024119 -0.084488  0.943026  0.076957      0\n",
            "598 -0.073484  0.090645 -0.351960 -0.181310      0\n",
            "\n",
            "[599 rows x 5 columns]\n",
            "            Attr1       Attr2       Attr3       Attr4       class\n",
            "count  599.000000  599.000000  599.000000  599.000000  599.000000\n",
            "mean    -0.062829    0.029413   -0.170557   -0.061271    0.338898\n",
            "std      0.235256    0.099197    1.012604    0.311390    0.473731\n",
            "min     -2.247368   -0.158814   -5.986769   -0.380847    0.000000\n",
            "25%     -0.120217   -0.033503   -0.743245   -0.213756    0.000000\n",
            "50%     -0.057000    0.021298   -0.179153   -0.153490    0.000000\n",
            "75%      0.037110    0.079595    0.474668   -0.030606    1.000000\n",
            "max      1.014406    0.706143    2.466681    2.480155    1.000000\n",
            "          Attr1     Attr2     Attr3     Attr4     class\n",
            "Attr1  1.000000 -0.392651  0.346724  0.281623 -0.284988\n",
            "Attr2 -0.392651  1.000000 -0.606317 -0.442061  0.303550\n",
            "Attr3  0.346724 -0.606317  1.000000  0.677746 -0.257445\n",
            "Attr4  0.281623 -0.442061  0.677746  1.000000 -0.230635\n",
            "class -0.284988  0.303550 -0.257445 -0.230635  1.000000\n",
            "Regression\n",
            "================================\n",
            "[[216  22]\n",
            " [ 86  35]]\n",
            "Regression TrainSet: Accurarcy 69.92%\n",
            "================================\n",
            "[[142  16]\n",
            " [ 59  23]]\n",
            "Regression Testset: Accurarcy 68.75%\n",
            "================================\n",
            "================================\n",
            "================================\n",
            "Decision Tree\n",
            "================================\n",
            "[[238   0]\n",
            " [  0 121]]\n",
            "Decsion Tree TrainSet: Accurarcy 100.00%\n",
            "================================\n",
            "[[121  37]\n",
            " [ 53  29]]\n",
            "Decision Tree Testset: Accurarcy 62.50%\n",
            "================================\n",
            "================================\n",
            "================================\n",
            "Random Forest\n",
            "================================\n",
            "[[205  33]\n",
            " [ 56  65]]\n",
            "Random Forest TrainSet: Accurarcy 75.21%\n",
            "================================\n",
            "[[132  26]\n",
            " [ 45  37]]\n",
            "Random Forest Testset: Accurarcy 70.42%\n",
            "================================\n",
            "================================\n",
            "================================\n",
            "Xgboost\n",
            "================================\n",
            "[[233   5]\n",
            " [ 15 106]]\n",
            "Xgboost TrainSet: Accurarcy 94.43%\n",
            "==================================\n",
            "Xgboost on testset confusion matrix\n",
            "[[124  34]\n",
            " [ 47  35]]\n",
            "Xgboost on TestSet: Accuracy 66.25%\n",
            "==================================\n",
            "12/12 [==============================] - 0s 1ms/step - loss: 0.6171 - accuracy: 0.6379\n",
            "Neural Network Trainset: \n",
            "accuracy: 63.79%\n",
            "==================================\n",
            "==================================\n",
            "Neural Network on testset confusion matrix\n",
            "[[123  35]\n",
            " [ 44  38]]\n",
            "Neural Network on TestSet: Accuracy 67.08%\n",
            "SVM (Classifier)\n",
            "================================\n",
            "Training confusion matrix: \n",
            "[[217  21]\n",
            " [ 76  45]]\n",
            "TrainSet: Accurarcy 72.98%\n",
            "================================\n",
            "[[138  20]\n",
            " [ 60  22]]\n",
            "Testset: Accurarcy 66.67%\n",
            "================================\n",
            "SVM (tol=0.0005)\n",
            "================================\n",
            "Training confusion matrix: \n",
            "[[217  21]\n",
            " [ 76  45]]\n",
            "TrainSet: Accurarcy 72.98%\n",
            "================================\n",
            "[[138  20]\n",
            " [ 60  22]]\n",
            "Testset: Accurarcy 66.67%\n",
            "================================\n",
            "SVM (degree=2)\n",
            "================================\n",
            "Training confusion matrix: \n",
            "[[217  21]\n",
            " [ 76  45]]\n",
            "TrainSet: Accurarcy 72.98%\n",
            "================================\n",
            "[[138  20]\n",
            " [ 60  22]]\n",
            "Testset: Accurarcy 66.67%\n",
            "================================\n",
            "SVM (RBF kernel)\n",
            "================================\n",
            "Training confusion matrix: \n",
            "[[217  21]\n",
            " [ 76  45]]\n",
            "TrainSet: Accurarcy 72.98%\n",
            "================================\n",
            "[[138  20]\n",
            " [ 60  22]]\n",
            "Testset: Accurarcy 66.67%\n",
            "================================\n",
            "SVM (sigmoid)\n",
            "================================\n",
            "Training confusion matrix: \n",
            "[[169  69]\n",
            " [ 68  53]]\n",
            "TrainSet: Accurarcy 61.84%\n",
            "================================\n",
            "[[113  45]\n",
            " [ 41  41]]\n",
            "Testset: Accurarcy 64.17%\n",
            "================================\n",
            "SVM (Linear)\n",
            "================================\n",
            "Training confusion matrix: \n",
            "[[230   8]\n",
            " [102  19]]\n",
            "TrainSet: Accurarcy 69.36%\n",
            "================================\n",
            "[[149   9]\n",
            " [ 70  12]]\n",
            "Testset: Accurarcy 67.08%\n",
            "================================\n",
            "SVM uneven class weight\n",
            "================================\n",
            "Training confusion matrix: \n",
            "[[158  80]\n",
            " [ 34  87]]\n",
            "TrainSet: Accurarcy 68.25%\n",
            "================================\n",
            "[[101  57]\n",
            " [ 22  60]]\n",
            "Testset: Accurarcy 67.08%\n",
            "================================\n",
            "Naive Bayes\n",
            "================================\n",
            "Training confusion matrix: \n",
            "[[183  55]\n",
            " [ 59  62]]\n",
            "TrainSet: Accurarcy 68.25%\n",
            "================================\n",
            "[[121  37]\n",
            " [ 37  45]]\n",
            "Testset: Accurarcy 69.17%\n",
            "================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLXptszenQpc"
      },
      "source": [
        "## Model helper function\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nSZP7j1dIBJ"
      },
      "source": [
        "## Feature importance\n",
        "\n",
        "### Feature importances with forests of trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "whZbWt0hdIBK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eeb2b90-890e-43be-8b6b-7a8857cd7fb3"
      },
      "source": [
        "RF = model3\n",
        "importances = RF.feature_importances_\n",
        "std = numpy.std([tree.feature_importances_ for tree in RF.estimators_],\n",
        "             axis=0)\n",
        "indices = numpy.argsort(importances)[::-1]\n",
        "\n",
        "# Print the feature ranking\n",
        "print(\"Feature ranking:\")\n",
        "\n",
        "for f in range(X.shape[1]):\n",
        "    print(\"%d. feature (Column index) %s (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature ranking:\n",
            "1. feature (Column index) 1 (0.498745)\n",
            "2. feature (Column index) 0 (0.315273)\n",
            "3. feature (Column index) 3 (0.106142)\n",
            "4. feature (Column index) 2 (0.079840)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuDxnhWGdIBh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "f40fa961-95be-4fcf-f0a8-fd4278993533"
      },
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "boxplot = pd.DataFrame(dataset).boxplot()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXFywaNXvGxt"
      },
      "source": [
        "## Remove outlier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vDI9ZQJvDq2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4984df25-3cad-4a06-805f-ac9871b74cab"
      },
      "source": [
        "df = pd.DataFrame(dataset)\n",
        "quantile = df.iloc[:,4].quantile(0.99)\n",
        "df1 = df[df.iloc[:,4] < quantile]\n",
        "df.shape, df1.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((599, 5), (396, 5))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGgSwffuvIRV"
      },
      "source": [
        "df1 = df1.dropna()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0oHOT1nvTkH"
      },
      "source": [
        "## Use top 3 features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRvAbgUivSsX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcd185bb-c3f6-47a0-a033-f2c3b22a4090"
      },
      "source": [
        "TOP_N_FEATURE = 2\n",
        "\n",
        "indices_top3 = indices[:TOP_N_FEATURE]\n",
        "print(indices_top3)\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "# load pima indians dataset\n",
        "# split into input (X) and output (Y) variables\n",
        "\n",
        "df = dataset\n",
        "print(df)\n",
        "df = pd.DataFrame(dataset)\n",
        "\n",
        "X = dataset.iloc[:,indices_top3]\n",
        "Y = dataset.iloc[:,Y_position]\n",
        "# create model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=2020)\n",
        "\n",
        "\n",
        "#scaling to around -2 to 2 (Z)\n",
        "scaler = preprocessing.StandardScaler().fit(X_train)\n",
        "scaled_X_train = scaler.transform(X_train)\n",
        "scaled_X_test = scaler.transform(X_test)\n",
        "\n",
        "#Model 1 : linear regression\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "#class sklearn.linear_model.LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, \n",
        "#intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', \n",
        "#verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
        "\n",
        "linear_classifier = linear_model.LogisticRegression(random_state=123)\n",
        "linear_classifier.fit(scaled_X_train, y_train)\n",
        "y_pred_train1 = linear_classifier.predict(scaled_X_train)\n",
        "cm1_train = confusion_matrix(y_train,y_pred_train1)\n",
        "print(\"Regression\")\n",
        "print(\"================================\")\n",
        "print(cm1_train)\n",
        "acc_train1 = (cm1_train[0,0] + cm1_train[1,1]) / sum(sum(cm1_train))\n",
        "print(\"Regression TrainSet: Accurarcy %.2f%%\" % (acc_train1*100))\n",
        "print(\"================================\")\n",
        "y_pred1 = linear_classifier.predict(scaled_X_test)\n",
        "cm1 = confusion_matrix(y_test,y_pred1)\n",
        "print(cm1)\n",
        "acc1 = (cm1[0,0] + cm1[1,1]) / sum(sum(cm1))\n",
        "print(\"Regression Testset: Accurarcy %.2f%%\" % (acc1*100))\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "\n",
        "\n",
        "#Model 2: decision tree\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
        "#class sklearn.tree.DecisionTreeClassifier(*, criterion='gini', splitter='best', max_depth=None, min_samples_split=2, \n",
        "#min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, \n",
        "#min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort='deprecated', ccp_alpha=0.0)\n",
        "\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "clf = clf.fit(scaled_X_train, y_train)\n",
        "y_pred_train2 = clf.predict(scaled_X_train)\n",
        "cm2_train = confusion_matrix(y_train,y_pred_train2)\n",
        "print(\"Decision Tree\")\n",
        "print(\"================================\")\n",
        "print(cm2_train)\n",
        "acc_train2 = (cm2_train[0,0] + cm2_train[1,1]) / sum(sum(cm2_train))\n",
        "print(\"Decsion Tree TrainSet: Accurarcy %.2f%%\" % (acc_train2*100))\n",
        "print(\"================================\")\n",
        "y_pred2 = clf.predict(scaled_X_test)\n",
        "cm2 = confusion_matrix(y_test,y_pred2)\n",
        "acc2 = (cm2[0,0] + cm2[1,1]) / sum(sum(cm2))\n",
        "print(cm2)\n",
        "print(\"Decision Tree Testset: Accurarcy %.2f%%\" % (acc2*100))\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "\n",
        "\n",
        "#Model 3 random forest\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "#class sklearn.ensemble.RandomForestClassifier(n_estimators=100, *, criterion='gini', max_depth=None, \n",
        "#min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', \n",
        "#max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, \n",
        "#n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)[source]\n",
        "\n",
        "model3 = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0)\n",
        "model3.fit(scaled_X_train, y_train)\n",
        "y_predicted3 = model3.predict(scaled_X_test)\n",
        "\n",
        "y_pred_train3 = model3.predict(scaled_X_train)\n",
        "cm3_train = confusion_matrix(y_train,y_pred_train3)\n",
        "print(\"Random Forest\")\n",
        "print(\"================================\")\n",
        "print(cm3_train)\n",
        "acc_train3 = (cm3_train[0,0] + cm3_train[1,1]) / sum(sum(cm3_train))\n",
        "print(\"Random Forest TrainSet: Accurarcy %.2f%%\" % (acc_train3*100))\n",
        "print(\"================================\")\n",
        "y_pred3 = model3.predict(scaled_X_test)\n",
        "cm_test3 = confusion_matrix(y_test,y_pred3)\n",
        "print(cm_test3)\n",
        "acc_test3 = (cm_test3[0,0] + cm_test3[1,1]) / sum(sum(cm_test3))\n",
        "print(\"Random Forest Testset: Accurarcy %.2f%%\" % (acc_test3*100))\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "\n",
        "#Model 4: XGBoost\n",
        "\n",
        "print(\"Xgboost\")\n",
        "print(\"================================\")\n",
        "#class sklearn.ensemble.GradientBoostingClassifier(*, loss='deviance', learning_rate=0.1, n_estimators=100, \n",
        "#subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
        "#max_depth=3, min_impurity_decrease=0.0, min_impurity_split=None, init=None, random_state=None, max_features=None, \n",
        "#verbose=0, max_leaf_nodes=None, warm_start=False, presort='deprecated', validation_fraction=0.1, \n",
        "#n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)[source]\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
        "\n",
        "model4 = GradientBoostingClassifier(random_state=0)\n",
        "model4.fit(scaled_X_train, y_train)\n",
        "y_pred_train4 = model4.predict(scaled_X_train)\n",
        "cm4_train = confusion_matrix(y_train,y_pred_train4)\n",
        "print(cm4_train)\n",
        "acc_train4 = (cm4_train[0,0] + cm4_train[1,1]) / sum(sum(cm4_train))\n",
        "print(\"Xgboost TrainSet: Accurarcy %.2f%%\" % (acc_train4*100))\n",
        "predictions = model4.predict(scaled_X_test)\n",
        "y_pred4 = (predictions > 0.5)\n",
        "y_pred4 =y_pred4*1 #convert to 0,1 instead of True False\n",
        "cm4 = confusion_matrix(y_test, y_pred4)\n",
        "print(\"==================================\")\n",
        "print(\"Xgboost on testset confusion matrix\")\n",
        "print(cm4)\n",
        "acc4 = (cm4[0,0] + cm4[1,1]) / sum(sum(cm4))\n",
        "print(\"Xgboost on TestSet: Accuracy %.2f%%\" % (acc4*100))\n",
        "print(\"==================================\")\n",
        "\n",
        "#Model 5: neural network\n",
        "#https://www.tensorflow.org/guide/keras/train_and_evaluate\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=TOP_N_FEATURE, activation='relu'))\n",
        "#model.add(Dense(10, activation='relu'))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# Compile mode\n",
        "# https://www.tensorflow.org/guide/keras/train_and_evaluate\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='Adamax', metrics=['accuracy'])\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=5, verbose=0)\n",
        "# evaluate the model\n",
        "scores = model.evaluate(X_train, y_train)\n",
        "#print(scores)\n",
        "print(\"Neural Network Trainset: \\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "predictions5 = model.predict(X_test)\n",
        "#print(predictions)\n",
        "#print('predictions shape:', predictions.shape)\n",
        "\n",
        "y_pred5 = (predictions5 > 0.5)\n",
        "y_pred5 = y_pred5*1 #convert to 0,1 instead of True False\n",
        "cm5 = confusion_matrix(y_test, y_pred5)\n",
        "print(\"==================================\")\n",
        "print(\"==================================\")\n",
        "print(\"Neural Network on testset confusion matrix\")\n",
        "print(cm5)\n",
        "\n",
        "## Get accurary from Confusion matrix\n",
        "## Position 0,0 and 1,1 are the correct predictions \n",
        "acc5 = (cm5[0,0] + cm5[1,1]) / sum(sum(cm5))\n",
        "print(\"Neural Network on TestSet: Accuracy %.2f%%\" % (acc5*100))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0]\n",
            "        Attr1     Attr2     Attr3     Attr4  class\n",
            "0   -0.086208 -0.041815 -0.007974 -0.082415      1\n",
            "1   -0.034655  0.013788  0.120081 -0.110792      1\n",
            "2   -0.454512  0.009128 -1.330367 -0.313777      1\n",
            "3   -1.856905  0.579749 -1.102942 -0.279015      1\n",
            "4   -0.055054  0.102515 -0.435038 -0.187300      1\n",
            "..        ...       ...       ...       ...    ...\n",
            "594 -0.100140  0.063698 -0.062937 -0.097755      0\n",
            "595 -0.022752  0.025541 -0.577176 -0.197877      0\n",
            "596 -0.164790 -0.023233 -0.374772 -0.172018      0\n",
            "597  0.024119 -0.084488  0.943026  0.076957      0\n",
            "598 -0.073484  0.090645 -0.351960 -0.181310      0\n",
            "\n",
            "[599 rows x 5 columns]\n",
            "Regression\n",
            "================================\n",
            "[[283  32]\n",
            " [119  45]]\n",
            "Regression TrainSet: Accurarcy 68.48%\n",
            "================================\n",
            "[[69 12]\n",
            " [26 13]]\n",
            "Regression Testset: Accurarcy 68.33%\n",
            "================================\n",
            "================================\n",
            "================================\n",
            "Decision Tree\n",
            "================================\n",
            "[[315   0]\n",
            " [  0 164]]\n",
            "Decsion Tree TrainSet: Accurarcy 100.00%\n",
            "================================\n",
            "[[60 21]\n",
            " [28 11]]\n",
            "Decision Tree Testset: Accurarcy 59.17%\n",
            "================================\n",
            "================================\n",
            "================================\n",
            "Random Forest\n",
            "================================\n",
            "[[275  40]\n",
            " [ 87  77]]\n",
            "Random Forest TrainSet: Accurarcy 73.49%\n",
            "================================\n",
            "[[65 16]\n",
            " [21 18]]\n",
            "Random Forest Testset: Accurarcy 69.17%\n",
            "================================\n",
            "================================\n",
            "================================\n",
            "Xgboost\n",
            "================================\n",
            "[[302  13]\n",
            " [ 34 130]]\n",
            "Xgboost TrainSet: Accurarcy 90.19%\n",
            "==================================\n",
            "Xgboost on testset confusion matrix\n",
            "[[64 17]\n",
            " [23 16]]\n",
            "Xgboost on TestSet: Accuracy 66.67%\n",
            "==================================\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.5549 - accuracy: 0.7015\n",
            "Neural Network Trainset: \n",
            "accuracy: 70.15%\n",
            "==================================\n",
            "==================================\n",
            "Neural Network on testset confusion matrix\n",
            "[[70 11]\n",
            " [26 13]]\n",
            "Neural Network on TestSet: Accuracy 69.17%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
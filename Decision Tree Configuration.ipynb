{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification_v2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6-final"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ce1il03S6_Te",
        "tags": [],
        "outputId": "8fc5e3a7-0463-4d0c-97d1-0bcbb11d16f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy\n",
        "from sklearn import linear_model\n",
        "from sklearn import preprocessing\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "\n",
        "Y_position = 4\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"/content/ETF Treynor.csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "\n",
        "\n",
        "\n",
        "X = dataset[:,0:Y_position]\n",
        "Y = dataset[:,Y_position]\n",
        "# create model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.40, random_state=2020)\n",
        "\n",
        "#scaling to around -2 to 2 (Z)\n",
        "scaler = preprocessing.StandardScaler().fit(X_train)\n",
        "scaled_X_train = scaler.transform(X_train)\n",
        "scaled_X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "#Model 2: decision tree\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
        "#class sklearn.tree.DecisionTreeClassifier(*, criterion='gini', splitter='best', max_depth=None, min_samples_split=2, \n",
        "#min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, \n",
        "#min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort='deprecated', ccp_alpha=0.0)\n",
        "\n",
        "clf = tree.DecisionTreeClassifier(criterion='entropy', min_samples_split=3, max_depth=3)\n",
        "clf = clf.fit(scaled_X_train, y_train)\n",
        "y_pred_train2 = clf.predict(scaled_X_train)\n",
        "cm2_train = confusion_matrix(y_train,y_pred_train2)\n",
        "print(\"Decision Tree\")\n",
        "print(\"================================\")\n",
        "print(cm2_train)\n",
        "acc_train2 = (cm2_train[0,0] + cm2_train[1,1]) / sum(sum(cm2_train))\n",
        "print(\"Decsion Tree TrainSet: Accurarcy %.2f%%\" % (acc_train2*100))\n",
        "print(\"================================\")\n",
        "y_pred2 = clf.predict(scaled_X_test)\n",
        "cm2 = confusion_matrix(y_test,y_pred2)\n",
        "acc2 = (cm2[0,0] + cm2[1,1]) / sum(sum(cm2))\n",
        "print(cm2)\n",
        "print(\"Decision Tree Testset: Accurarcy %.2f%%\" % (acc2*100))\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decision Tree\n",
            "================================\n",
            "[[131  19]\n",
            " [ 52 115]]\n",
            "Decsion Tree TrainSet: Accurarcy 77.60%\n",
            "================================\n",
            "[[103  12]\n",
            " [ 29  68]]\n",
            "Decision Tree Testset: Accurarcy 80.66%\n",
            "================================\n",
            "================================\n",
            "================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nSZP7j1dIBJ"
      },
      "source": [
        "## Feature importance\n",
        "\n",
        "### Feature importances with forests of trees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXFywaNXvGxt"
      },
      "source": [
        "## Remove outlier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0oHOT1nvTkH"
      },
      "source": [
        "## Use top 3 features"
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_DHZn5aS3Ib",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "fd53c2e3-0e7a-4934-886d-65fa37084ecf"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "timesteps = 3\n",
        "data_size = 10000 # datasize selected must have both attack and normal data.\n",
        "data_resize = int(data_size//timesteps) #data_size/timesteps using // because round down, example 10/3=3\n",
        "data_trunc_size = data_resize * timesteps # remove extra rows for so that data can be divided by timesteps\n",
        "\n",
        "num_classes = timesteps # follow timestep\n",
        "data_dim = 36\n",
        "batchsize = 32 # number of data in a batch\n",
        "drop = 0.2\n",
        "\n",
        "#%%\n",
        "# load dataset\n",
        "dataset = pd.read_csv(\"CyberSecurity.csv\")\n",
        "dataset.drop(columns=[\"Timestamp1\", \"AIT402\",\"FIT401\",\"LIT401\",\"P402\",\"UV401\",\"AIT501\",\"AIT502\",\"FIT501\",\"FIT502\",\"FIT503\",\"FIT504\",\"P501\",\"PIT501\",\"PIT502\",\"PIT503\",\"Normal/Attack\"],inplace=True)\n",
        "x_data = dataset.iloc[:,0:data_dim].values\n",
        "y_data = dataset.iloc[:,data_dim].values\n",
        "\n",
        "# Reduce the size of data so that the data can be divided by time step\n",
        "# split into input (X) and output (Y) variables\n",
        "X = x_data[:data_trunc_size,0:data_dim]\n",
        "Y = y_data[:data_trunc_size]\n",
        "\n",
        "# required format for lstm\n",
        "X_shaped = X.reshape(data_resize, timesteps, data_dim) \n",
        "Y_shaped = Y.reshape(data_resize,timesteps)\n",
        "\n",
        "print(\"X shape is : {}\".format(X_shaped.shape))\n",
        "print(\"Y shape is : {}\".format(Y_shaped.shape))\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_shaped, Y_shaped, test_size=0.3)\n",
        "\n",
        "# Create the model\n",
        "# expected input data shape: (batch_size, timesteps, data_dim)\n",
        "# Dropout used to prevent over-fitting.\n",
        "# Input shape will infer the batch size by itself\n",
        "# We are using binary cross entropy even when num_class can be > 1 because this is a binary classification on an array\n",
        "# For multiclass classification, use categorical cross-entropy\n",
        "model = Sequential()\n",
        "model.add(LSTM(36, return_sequences=True, input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 40\n",
        "model.add(Dropout(drop))\n",
        "model.add(LSTM(36,return_sequences=True))  # returns a sequence of vectors of dimension 40\n",
        "model.add(Dropout(drop))\n",
        "model.add(LSTM(36,return_sequences=True))  # returns a sequence of vectors of dimension 40\n",
        "model.add(Dropout(drop))\n",
        "model.add(LSTM(36))  # return a single vector of dimension 40\n",
        "model.add(Dropout(drop))\n",
        "model.add(Dense(num_classes, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, batch_size= batchsize, epochs=1, validation_data= (X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "# Returns you the accuracy and loss\n",
        "loss, acc = model.evaluate(X_train, y_train,timesteps)\n",
        "print(\"Keras: \\n%s: %.2f%%\" % (model.metrics_names[1], acc*100))\n",
        "\n",
        "# Shape of prediction is nrow * timestep\n",
        "# Result would be that same as keras evaluate\n",
        "proba = model.predict(X_test)\n",
        "\n",
        "# proba is the probability. Here we set threshold as 0.5 to be considered true.\n",
        "print('predictions shape:', proba.shape)\n",
        "y_pred = proba > 0.3\n",
        "# Reshape to a single dimension for comparison and to create confusion matrix\n",
        "y_pred_single_dim = y_pred.reshape(proba.shape[0]*proba.shape[1])\n",
        "y_test_single_dim = y_test.reshape(y_test.shape[0]*y_test.shape[1])\n",
        "print(y_pred_single_dim)\n",
        "print(y_test_single_dim)\n",
        "matrix = confusion_matrix(y_test_single_dim, y_pred_single_dim)\n",
        "print(\"Keras: \\n%s: %.2f%%\" % (model.metrics_names[1], sum(y_pred_single_dim==y_test_single_dim)/len(y_test_single_dim)*100))\n",
        "print(matrix)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X shape is : (3333, 3, 36)\n",
            "Y shape is : (3333, 3)\n",
            "73/73 [==============================] - 2s 23ms/step - loss: 0.5944 - accuracy: 0.3519 - val_loss: 0.5414 - val_accuracy: 0.8540\n",
            "778/778 [==============================] - 1s 2ms/step - loss: 0.5445 - accuracy: 0.8650\n",
            "Keras: \n",
            "accuracy: 86.50%\n",
            "predictions shape: (1000, 3)\n",
            "[False False False ... False False False]\n",
            "[0 0 0 ... 1 1 1]\n",
            "Keras: \n",
            "accuracy: 85.47%\n",
            "[[2144   21]\n",
            " [ 415  420]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
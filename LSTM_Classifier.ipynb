{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM Classifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_DHZn5aS3Ib",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "24379873-e0ef-45fe-93b5-d2a95d8dd741"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import csv\n",
        "\n",
        "timesteps = 3\n",
        "data_size = 10000 # datasize selected must have both attack and normal data.\n",
        "data_resize = int(data_size//timesteps) #data_size/timesteps using // because round down, example 10/3=3\n",
        "data_trunc_size = data_resize * timesteps # remove extra rows for so that data can be divided by timesteps\n",
        "\n",
        "num_classes = timesteps # follow timestep\n",
        "data_dim = 36\n",
        "batchsize = 32 # number of data in a batch\n",
        "drop = 0.2\n",
        "\n",
        "#%%\n",
        "# load dataset\n",
        "dataset = pd.read_csv(\"CyberSecurity LSTM Classification.csv\")\n",
        "\n",
        "df = pd.DataFrame(dataset)\n",
        "print(df)\n",
        "\t# summary statistics\n",
        "print(df.describe())\n",
        "\n",
        "corr=df.corr(method ='pearson')\n",
        "print(corr)\n",
        "corr.to_csv('corr.csv')\n",
        "\n",
        "\n",
        "dataset.drop(columns=[\"Timestamp1\", \"AIT402\",\"FIT401\",\"LIT401\",\"P402\",\"UV401\",\"AIT501\",\"AIT502\",\"FIT501\",\"FIT502\",\"FIT503\",\"FIT504\",\"P501\",\"PIT501\",\"PIT502\",\"PIT503\",\"Normal/Attack\"],inplace=True)\n",
        "x_data = dataset.iloc[:,0:data_dim].values\n",
        "y_data = dataset.iloc[:,data_dim].values\n",
        "\n",
        "# Reduce the size of data so that the data can be divided by time step\n",
        "# split into input (X) and output (Y) variables\n",
        "X = x_data[:data_trunc_size,0:data_dim]\n",
        "Y = y_data[:data_trunc_size]\n",
        "\n",
        "# required format for lstm\n",
        "X_shaped = X.reshape(data_resize, timesteps, data_dim) \n",
        "Y_shaped = Y.reshape(data_resize,timesteps)\n",
        "\n",
        "print(\"X shape is : {}\".format(X_shaped.shape))\n",
        "print(\"Y shape is : {}\".format(Y_shaped.shape))\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_shaped, Y_shaped, test_size=0.3)\n",
        "\n",
        "# Create the model\n",
        "# expected input data shape: (batch_size, timesteps, data_dim)\n",
        "# Dropout used to prevent over-fitting.\n",
        "# Input shape will infer the batch size by itself\n",
        "# We are using binary cross entropy even when num_class can be > 1 because this is a binary classification on an array\n",
        "# For multiclass classification, use categorical cross-entropy\n",
        "model = Sequential()\n",
        "model.add(LSTM(36, return_sequences=True, input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 40\n",
        "model.add(Dropout(drop))\n",
        "model.add(LSTM(36,return_sequences=True))  # returns a sequence of vectors of dimension 40\n",
        "model.add(Dropout(drop))\n",
        "model.add(LSTM(36,return_sequences=True))  # returns a sequence of vectors of dimension 40\n",
        "model.add(Dropout(drop))\n",
        "model.add(LSTM(36))  # return a single vector of dimension 40\n",
        "model.add(Dropout(drop))\n",
        "model.add(Dense(num_classes, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, batch_size= batchsize, epochs=1, validation_data= (X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "# Returns you the accuracy and loss\n",
        "loss, acc = model.evaluate(X_train, y_train,timesteps)\n",
        "print(\"Keras: \\n%s: %.2f%%\" % (model.metrics_names[1], acc*100))\n",
        "\n",
        "# Shape of prediction is nrow * timestep\n",
        "# Result would be that same as keras evaluate\n",
        "proba = model.predict(X_test)\n",
        "\n",
        "# proba is the probability. Here we set threshold as 0.5 to be considered true.\n",
        "print('predictions shape:', proba.shape)\n",
        "y_pred = proba > 0.3\n",
        "# Reshape to a single dimension for comparison and to create confusion matrix\n",
        "y_pred_single_dim = y_pred.reshape(proba.shape[0]*proba.shape[1])\n",
        "y_test_single_dim = y_test.reshape(y_test.shape[0]*y_test.shape[1])\n",
        "print(y_pred_single_dim)\n",
        "print(y_test_single_dim)\n",
        "matrix = confusion_matrix(y_test_single_dim, y_pred_single_dim)\n",
        "print(\"Keras: \\n%s: %.2f%%\" % (model.metrics_names[1], sum(y_pred_single_dim==y_test_single_dim)/len(y_test_single_dim)*100))\n",
        "print(matrix)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                   Timestamp1    FIT101    LIT101  ...  P603  Normal/Attack  Attack\n",
            "0      28/12/2015 10:00:00 AM  2.427057  522.8467  ...     1         Normal       0\n",
            "1      28/12/2015 10:00:01 AM  2.446274  522.8860  ...     1         Normal       0\n",
            "2      28/12/2015 10:00:02 AM  2.489191  522.8467  ...     1         Normal       0\n",
            "3      28/12/2015 10:00:03 AM  2.534350  522.9645  ...     1         Normal       0\n",
            "4      28/12/2015 10:00:04 AM  2.569260  523.4748  ...     1         Normal       0\n",
            "...                       ...       ...       ...  ...   ...            ...     ...\n",
            "9995   28/12/2015 12:46:35 PM  0.000000  810.6872  ...     1         Normal       0\n",
            "9996   28/12/2015 12:46:36 PM  0.000000  810.6479  ...     1         Normal       0\n",
            "9997   28/12/2015 12:46:37 PM  0.000000  810.8442  ...     1         Normal       0\n",
            "9998   28/12/2015 12:46:38 PM  0.000000  811.0012  ...     1         Normal       0\n",
            "9999   28/12/2015 12:46:39 PM  0.000000  810.6872  ...     1         Normal       0\n",
            "\n",
            "[10000 rows x 54 columns]\n",
            "             FIT101        LIT101  ...     P603        Attack\n",
            "count  10000.000000  10000.000000  ...  10000.0  10000.000000\n",
            "mean       1.915416    656.324375  ...      1.0      0.278100\n",
            "std        1.097364    132.321916  ...      0.0      0.448085\n",
            "min        0.000000    488.068800  ...      1.0      0.000000\n",
            "25%        2.217036    513.033600  ...      1.0      0.000000\n",
            "50%        2.542036    673.030050  ...      1.0      0.000000\n",
            "75%        2.555168    749.649200  ...      1.0      1.000000\n",
            "max        2.687442    925.032300  ...      1.0      1.000000\n",
            "\n",
            "[8 rows x 52 columns]\n",
            "           FIT101    LIT101     MV101      P101  ...  P601      P602  P603    Attack\n",
            "FIT101   1.000000 -0.298459  0.954178  0.246174  ...   NaN -0.043323   NaN  0.092430\n",
            "LIT101  -0.298459  1.000000 -0.307484 -0.284165  ...   NaN -0.049381   NaN  0.154976\n",
            " MV101   0.954178 -0.307484  1.000000  0.254269  ...   NaN -0.040561   NaN  0.079019\n",
            "P101     0.246174 -0.284165  0.254269  1.000000  ...   NaN  0.049971   NaN -0.035804\n",
            "P102    -0.302655 -0.120232 -0.290465  0.137654  ...   NaN  0.169942   NaN  0.323887\n",
            " AIT201  0.015225  0.064934  0.015892 -0.186919  ...   NaN -0.009213   NaN -0.028984\n",
            "AIT202  -0.110237  0.193150 -0.111924 -0.181848  ...   NaN  0.006297   NaN -0.184318\n",
            "AIT203   0.160823 -0.224773  0.174031  0.950163  ...   NaN  0.040348   NaN -0.012674\n",
            "FIT201   0.228909 -0.291868  0.237480  0.987933  ...   NaN  0.060508   NaN -0.019849\n",
            " MV201   0.236894 -0.277812  0.244542  0.986318  ...   NaN  0.049287   NaN -0.036294\n",
            " P201         NaN       NaN       NaN       NaN  ...   NaN       NaN   NaN       NaN\n",
            " P202         NaN       NaN       NaN       NaN  ...   NaN       NaN   NaN       NaN\n",
            "P203     0.218861 -0.236834  0.226363  0.946077  ...   NaN  0.052634   NaN -0.099855\n",
            " P204         NaN       NaN       NaN       NaN  ...   NaN       NaN   NaN       NaN\n",
            "P205     0.247668 -0.289787  0.255622  0.991759  ...   NaN  0.050214   NaN -0.041841\n",
            "P206          NaN       NaN       NaN       NaN  ...   NaN       NaN   NaN       NaN\n",
            "DPIT301  0.117645 -0.237370  0.134763  0.450139  ...   NaN -0.168853   NaN  0.092646\n",
            "FIT301   0.079244 -0.238907  0.099262  0.442044  ...   NaN -0.151129   NaN  0.092070\n",
            "LIT301   0.145009 -0.341765  0.134289 -0.456145  ...   NaN -0.015667   NaN  0.011711\n",
            "MV301   -0.021095 -0.026622 -0.019840  0.026339  ...   NaN  0.805488   NaN  0.018146\n",
            "MV302    0.134161 -0.220996  0.148536  0.426583  ...   NaN -0.135577   NaN  0.084282\n",
            " MV303  -0.059523 -0.074045 -0.055404  0.067716  ...   NaN  0.518068   NaN  0.051076\n",
            "MV304   -0.119546 -0.014583 -0.111568 -0.017961  ...   NaN -0.009218   NaN  0.012956\n",
            "P301          NaN       NaN       NaN       NaN  ...   NaN       NaN   NaN       NaN\n",
            "P302     0.071886 -0.225297  0.091930  0.424982  ...   NaN -0.152178   NaN  0.083701\n",
            "AIT401   0.084613 -0.180958  0.084704  0.094260  ...   NaN -0.011577   NaN  0.112886\n",
            "AIT402   0.586616 -0.365498  0.576615  0.492749  ...   NaN  0.055496   NaN  0.050897\n",
            "FIT401   0.372436 -0.027115  0.354759  0.182294  ...   NaN  0.035110   NaN -0.107790\n",
            "LIT401   0.525784 -0.321092  0.516642  0.224500  ...   NaN  0.023276   NaN -0.148141\n",
            "P401          NaN       NaN       NaN       NaN  ...   NaN       NaN   NaN       NaN\n",
            "P402          NaN       NaN       NaN       NaN  ...   NaN       NaN   NaN       NaN\n",
            "P403          NaN       NaN       NaN       NaN  ...   NaN       NaN   NaN       NaN\n",
            "P404          NaN       NaN       NaN       NaN  ...   NaN       NaN   NaN       NaN\n",
            "UV401         NaN       NaN       NaN       NaN  ...   NaN       NaN   NaN       NaN\n",
            "AIT501  -0.221316 -0.159467 -0.212258 -0.317849  ...   NaN -0.023943   NaN -0.031198\n",
            "AIT502   0.606004 -0.367261  0.593283  0.484768  ...   NaN  0.033621   NaN  0.047383\n",
            "AIT503   0.313289 -0.160983  0.305265 -0.098945  ...   NaN -0.099270   NaN -0.168124\n",
            "AIT504   0.224393  0.005683  0.220758  0.045078  ...   NaN -0.063389   NaN -0.258152\n",
            "FIT501   0.356025 -0.029399  0.338568  0.165898  ...   NaN  0.016253   NaN -0.124221\n",
            "FIT502   0.063932  0.099866  0.049333  0.025587  ...   NaN -0.008940   NaN -0.059817\n",
            "FIT503  -0.150437 -0.103425 -0.139769 -0.108048  ...   NaN  0.010053   NaN  0.124895\n",
            "FIT504  -0.289923  0.047769 -0.279644 -0.127577  ...   NaN -0.013053   NaN  0.124727\n",
            "P501          NaN       NaN       NaN       NaN  ...   NaN       NaN   NaN       NaN\n",
            "P502          NaN       NaN       NaN       NaN  ...   NaN       NaN   NaN       NaN\n",
            "PIT501   0.167153 -0.125915  0.159730  0.029249  ...   NaN -0.005165   NaN  0.003872\n",
            "PIT502   0.197166 -0.006983  0.177296  0.004821  ...   NaN -0.015989   NaN -0.028261\n",
            "PIT503   0.193925 -0.134675  0.185826  0.029374  ...   NaN -0.007397   NaN -0.006417\n",
            "FIT601  -0.046664 -0.054893 -0.043965  0.054002  ...   NaN  0.802435   NaN  0.040531\n",
            "P601          NaN       NaN       NaN       NaN  ...   NaN       NaN   NaN       NaN\n",
            "P602    -0.043323 -0.049381 -0.040561  0.049971  ...   NaN  1.000000   NaN  0.037365\n",
            "P603          NaN       NaN       NaN       NaN  ...   NaN       NaN   NaN       NaN\n",
            "Attack   0.092430  0.154976  0.079019 -0.035804  ...   NaN  0.037365   NaN  1.000000\n",
            "\n",
            "[52 rows x 52 columns]\n",
            "X shape is : (3333, 3, 36)\n",
            "Y shape is : (3333, 3)\n",
            "73/73 [==============================] - 2s 23ms/step - loss: 0.5431 - accuracy: 0.3236 - val_loss: 0.4878 - val_accuracy: 0.3990\n",
            "778/778 [==============================] - 1s 2ms/step - loss: 0.4909 - accuracy: 0.3712\n",
            "Keras: \n",
            "accuracy: 37.12%\n",
            "predictions shape: (1000, 3)\n",
            "[False False False ... False False False]\n",
            "[0 0 0 ... 0 0 0]\n",
            "Keras: \n",
            "accuracy: 80.57%\n",
            "[[1976  183]\n",
            " [ 400  441]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
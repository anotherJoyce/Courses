{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6-final"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ce1il03S6_Te",
        "colab_type": "code",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2789a77f-0ffb-4868-f438-2fd89f7ef724"
      },
      "source": [
        "# Create your first MLP in Keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn import linear_model\n",
        "from sklearn import preprocessing\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "Y_position = 5\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "np.random.seed(7)\n",
        "\n",
        "dataset = np.loadtxt(\"Alumni Giving Regression (Edited).csv\", delimiter=\",\")\n",
        "# split into input (X) and output (Y) variables\n",
        "\n",
        "df = pd.DataFrame(dataset)\n",
        "print(df)\n",
        "\t# summary statistics\n",
        "print(df.describe())\n",
        "\n",
        "corr=df.corr(method ='pearson')\n",
        "print(corr)\n",
        "corr.to_csv('corr.csv')\n",
        "\n",
        "X = dataset[:,0:Y_position]\n",
        "Y = dataset[:,Y_position]\n",
        "# create model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=2020)\n",
        "\n",
        "\n",
        "#Model 1 : linear regression\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
        "#class sklearn.linear_model.LinearRegression(*, fit_intercept=True, normalize=False, copy_X=True, n_jobs=None)\n",
        "\n",
        "model1 = linear_model.LinearRegression()\n",
        "model1.fit(X_train, y_train)\n",
        "y_pred_train1 = model1.predict(X_train)\n",
        "print(\"Regression\")\n",
        "print(\"================================\")\n",
        "RMSE_train1 = np.sqrt(np.mean(y_pred_train1-y_train)**2)\n",
        "print(\"Regression TrainSet: RMSE {}\".format(RMSE_train1))\n",
        "print(\"================================\")\n",
        "y_pred1 = model1.predict(X_test)\n",
        "RMSE_test1 = np.sqrt(np.mean(y_pred1-y_test)**2)\n",
        "print(\"Regression Testset: RMSE {}\".format(RMSE_test1))\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "\n",
        "\n",
        "#Model 2 decision tree\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
        "\n",
        "\n",
        "model2 = tree.DecisionTreeRegressor()\n",
        "model2.fit(X_train, y_train)\n",
        "print(\"Decision Tree\")\n",
        "print(\"================================\")\n",
        "y_pred_train2 = model2.predict(X_train)\n",
        "RMSE_train2 = np.sqrt(np.mean(y_pred_train2-y_train)**2)\n",
        "print(\"Decision Tree TrainSet: RMSE {}\".format(RMSE_train2))\n",
        "print(\"================================\")\n",
        "y_pred_test2 = model2.predict(X_test)\n",
        "RMSE_test2 = np.sqrt(np.mean(y_pred_test2-y_test)**2)\n",
        "print(\"Decision Tree TestSet: RMSE {}\".format(RMSE_test2))\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "\n",
        "\n",
        "#Model 3 Random Forest\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
        "#class sklearn.ensemble.RandomForestRegressor(n_estimators=100, *, criterion='mse', max_depth=None, min_samples_split=2, \n",
        "#min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
        "#min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, \n",
        "#warm_start=False, ccp_alpha=0.0, max_samples=None)\n",
        "\n",
        "model3 = RandomForestRegressor()\n",
        "model3.fit(X_train, y_train)\n",
        "print(\"Random Forest Regressor\")\n",
        "print(\"================================\")\n",
        "y_pred_train3 = model3.predict(X_train)\n",
        "RMSE_train3 = np.sqrt(np.mean(y_pred_train3-y_train)**2)\n",
        "print(\"Random Forest Regressor TrainSet: RMSE {}\".format(RMSE_train3))\n",
        "print(\"================================\")\n",
        "y_pred_test3 = model3.predict(X_test)\n",
        "RMSE_test3 = np.sqrt(np.mean(y_pred_test3-y_test)**2)\n",
        "print(\"Random Forest Regressor TestSet: RMSE {}\".format(RMSE_test3))\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "\n",
        "\n",
        "#model 4: XgBoost\n",
        "#https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\n",
        "#class sklearn.ensemble.GradientBoostingRegressor(*, loss='ls', learning_rate=0.1, n_estimators=100, subsample=1.0, \n",
        "#criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, \n",
        "#min_impurity_decrease=0.0, min_impurity_split=None, init=None, random_state=None, max_features=None, alpha=0.9, \n",
        "#verbose=0, max_leaf_nodes=None, warm_start=False, presort='deprecated', validation_fraction=0.1, n_iter_no_change=None, \n",
        "#tol=0.0001, ccp_alpha=0.0)\n",
        "\n",
        "model4 = GradientBoostingRegressor()\n",
        "model4.fit(X_train, y_train)\n",
        "print(\"Gradient Boosting Regressor\")\n",
        "print(\"================================\")\n",
        "y_pred_train4 = model4.predict(X_train)\n",
        "RMSE_train4 = np.sqrt(np.mean(y_pred_train4-y_train)**2)\n",
        "print(\"Gradient Boosting Regressor TrainSet: RMSE {}\".format(RMSE_train4))\n",
        "print(\"================================\")\n",
        "y_pred_test4 = model4.predict(X_test)\n",
        "RMSE_test4 = np.sqrt(np.mean(y_pred_test4-y_test)**2)\n",
        "print(\"Gradient Boosting Regressor TestSet: RMSE {}\".format(RMSE_test4))\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "\n",
        "#Model 5: neural network\n",
        "#https://www.tensorflow.org/guide/keras/train_and_evaluate\n",
        "\n",
        "print(\"Neural Network\")\n",
        "print(\"================================\")\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=Y_position, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "# Compile mode\n",
        "# https://www.tensorflow.org/guide/keras/train_and_evaluate\n",
        "model.compile(loss='MSE', optimizer='Adamax', metrics=['accuracy'])\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, epochs=300, batch_size=5, verbose=0)\n",
        "# evaluate the model\n",
        "predictions5 = model.predict(X_train)\n",
        "RMSE_train5 = np.sqrt(np.mean(predictions5-y_train)**2)\n",
        "print(\"Neural Network TrainSet: RMSE {}\".format(RMSE_train5))\n",
        "print(\"==================================\")\n",
        "predictions5 = model.predict(X_test)\n",
        "RMSE_test5 = np.sqrt(np.mean(predictions5-y_test)**2)\n",
        "print(\"Neural Network TestSet: RMSE {}\".format(RMSE_test5))\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "print(\"================================\")\n",
        "\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        0     1     2     3     4     5\n",
            "0    24.0  0.42  0.16  0.59  0.81  0.08\n",
            "1    19.0  0.49  0.04  0.37  0.69  0.11\n",
            "2    18.0  0.24  0.17  0.66  0.87  0.31\n",
            "3     8.0  0.74  0.00  0.81  0.88  0.11\n",
            "4     8.0  0.95  0.00  0.86  0.92  0.28\n",
            "..    ...   ...   ...   ...   ...   ...\n",
            "118  11.0  0.54  0.03  0.89  0.94  0.29\n",
            "119  15.0  0.37  0.22  0.69  0.83  0.13\n",
            "120  23.0  0.32  0.19  0.59  0.80  0.12\n",
            "121  19.0  0.43  0.06  0.49  0.73  0.13\n",
            "122  19.0  0.36  0.11  0.52  0.74  0.10\n",
            "\n",
            "[123 rows x 6 columns]\n",
            "                0           1           2           3           4           5\n",
            "count  123.000000  123.000000  123.000000  123.000000  123.000000  123.000000\n",
            "mean    17.772358    0.403659    0.136260    0.645203    0.841138    0.141789\n",
            "std      4.517385    0.133897    0.060101    0.169794    0.083942    0.080674\n",
            "min      6.000000    0.140000    0.000000    0.260000    0.580000    0.020000\n",
            "25%     16.000000    0.320000    0.095000    0.505000    0.780000    0.080000\n",
            "50%     18.000000    0.380000    0.130000    0.640000    0.840000    0.130000\n",
            "75%     20.000000    0.460000    0.180000    0.785000    0.910000    0.170000\n",
            "max     31.000000    0.950000    0.310000    0.960000    0.980000    0.410000\n",
            "          0         1         2         3         4         5\n",
            "0  1.000000 -0.691900  0.414978 -0.604574 -0.521985 -0.549244\n",
            "1 -0.691900  1.000000 -0.581516  0.487248  0.376735  0.540427\n",
            "2  0.414978 -0.581516  1.000000  0.017023  0.055766 -0.175102\n",
            "3 -0.604574  0.487248  0.017023  1.000000  0.934396  0.681660\n",
            "4 -0.521985  0.376735  0.055766  0.934396  1.000000  0.647625\n",
            "5 -0.549244  0.540427 -0.175102  0.681660  0.647625  1.000000\n",
            "Regression\n",
            "================================\n",
            "Regression TrainSet: RMSE 5.721047218731674e-17\n",
            "================================\n",
            "Regression Testset: RMSE 0.023664087092633547\n",
            "================================\n",
            "================================\n",
            "================================\n",
            "Decision Tree\n",
            "================================\n",
            "Decision Tree TrainSet: RMSE 2.1241511950736413e-19\n",
            "================================\n",
            "Decision Tree TestSet: RMSE 0.028799999999999996\n",
            "================================\n",
            "================================\n",
            "================================\n",
            "================================\n",
            "Random Forest Regressor\n",
            "================================\n",
            "Random Forest Regressor TrainSet: RMSE 0.0008581632653061467\n",
            "================================\n",
            "Random Forest Regressor TestSet: RMSE 0.024839999999999984\n",
            "================================\n",
            "================================\n",
            "================================\n",
            "================================\n",
            "Gradient Boosting Regressor\n",
            "================================\n",
            "Gradient Boosting Regressor TrainSet: RMSE 2.8322015934315216e-19\n",
            "================================\n",
            "Gradient Boosting Regressor TestSet: RMSE 0.021170355230897102\n",
            "================================\n",
            "================================\n",
            "================================\n",
            "================================\n",
            "Neural Network\n",
            "================================\n",
            "Neural Network TrainSet: RMSE 0.13673469387755105\n",
            "==================================\n",
            "Neural Network TestSet: RMSE 0.1616\n",
            "================================\n",
            "================================\n",
            "================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8udZRBY9i4s",
        "colab_type": "text"
      },
      "source": [
        "## Feature importance\n",
        "\n",
        "### Feature importances with forests of trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "QkmdTElF9i4t",
        "colab_type": "code",
        "colab": {},
        "outputId": "35d143cb-7740-4905-a05e-70a76fa077e5"
      },
      "source": [
        "import numpy\n",
        "RF = model3\n",
        "importances = RF.feature_importances_\n",
        "std = numpy.std([tree.feature_importances_ for tree in RF.estimators_],\n",
        "             axis=0)\n",
        "indices = numpy.argsort(importances)[::-1]\n",
        "\n",
        "# Print the feature ranking\n",
        "print(\"Feature ranking:\")\n",
        "\n",
        "for f in range(X.shape[1]):\n",
        "    print(\"%d. feature (Column index) %s (%f)\" % (f + 1, indices[f], importances[indices[f]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature ranking:\n",
            "1. feature (Column index) 6 (0.685489)\n",
            "2. feature (Column index) 0 (0.232751)\n",
            "3. feature (Column index) 5 (0.027425)\n",
            "4. feature (Column index) 3 (0.021693)\n",
            "5. feature (Column index) 4 (0.014518)\n",
            "6. feature (Column index) 1 (0.011806)\n",
            "7. feature (Column index) 2 (0.006317)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZtZ3asl9i4w",
        "colab_type": "text"
      },
      "source": [
        "## Permutation feature importance\n",
        "\n",
        "### Apply this to any sklearn model\n",
        "\n",
        "-Permutation importance does not reflect to the intrinsic predictive value of a feature by itself but how important this feature is for a particular model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "lQTKvwhI9i4w",
        "colab_type": "code",
        "colab": {},
        "outputId": "e4017e39-2e8b-4cd6-f131-f7a4bf48aa06"
      },
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "r = permutation_importance(model1, X_test, y_test, n_repeats=30, random_state=0)\n",
        "\n",
        "for i in r.importances_mean.argsort()[::-1]:\n",
        "     if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
        "         print(f\"{'Feature '+str(i)+'   : ' }\"\n",
        "               f\"{r.importances_mean[i]:.3f}\"\n",
        "               f\" +/- {r.importances_std[i]:.3f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature 5   : 1.319 +/- 0.295\n",
            "Feature 6   : 0.823 +/- 0.291\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCgQu4rQ9i4z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
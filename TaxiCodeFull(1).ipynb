{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TaxiCodeFull.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SWys5jC4iEO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12ffa3f1-a2d1-46eb-a8d6-6b0159f94de2"
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import random\n",
        "from IPython.display import clear_output\n",
        "from IPython.display import Markdown, display\n",
        "def printmd(string):\n",
        "    display(Markdown(string))\n",
        "\n",
        "# https://towardsdatascience.com/reinforcement-learning-with-python-8ef0242a2fa2\n",
        "# Init Taxi-V2 Env\n",
        "env = gym.make(\"Taxi-v3\").env\n",
        "\n",
        "# Init arbitary values\n",
        "q_table = np.zeros([env.observation_space.n, env.action_space.n])\n",
        "\n",
        "# Hyperparameters\n",
        "alpha = 0.7 # Momemtum 0.2, Current 0.8 Greedy, 0.2 is to reduce volatality and flip flop\n",
        "gamma = 0.2 # Learning Rate 0.1 Greedyness is 10%\n",
        "epsilon = 0.4 # explore 10% exploit 90%\n",
        "\n",
        "\n",
        "all_epochs = []\n",
        "all_penalties = []\n",
        "training_memory = []\n",
        "\n",
        "for i in range(1, 50000):\n",
        "    state = env.reset()\n",
        "\n",
        "    # Init Vars\n",
        "    epochs, penalties, reward, = 0, 0, 0\n",
        "    done = False\n",
        "\n",
        "    #training\n",
        "    while not done:\n",
        "        if random.uniform(0, 1) < epsilon: \n",
        "            # Check the action space\n",
        "            action = env.action_space.sample() # for explore\n",
        "        else:\n",
        "            # Check the learned values\n",
        "            action = np.argmax(q_table[state]) # for exploit\n",
        "\n",
        "        next_state, reward, done, info = env.step(action) #gym generate, the environment already setup for you\n",
        "\n",
        "        old_value = q_table[state, action]\n",
        "        next_max = np.max(q_table[next_state]) #take highest from q table for exploit\n",
        "\n",
        "        # Update the new value\n",
        "        new_value = (1 - alpha) * old_value + alpha * \\\n",
        "            (reward + gamma * next_max)\n",
        "        q_table[state, action] = new_value        \n",
        "        \n",
        "        # penalty for performance evaluation\n",
        "        if reward == -10:\n",
        "            penalties += 1\n",
        "\n",
        "        state = next_state\n",
        "        epochs += 1\n",
        "    \n",
        "\n",
        "    if i % 100 == 0:\n",
        "        training_memory.append(q_table.copy())\n",
        "        clear_output(wait=True)\n",
        "        print(\"Episode:\", i)\n",
        "        print(\"Saved q_table during training:\", i)\n",
        "\n",
        "print(\"Training finished.\")\n",
        "print(q_table)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode: 49900\n",
            "Saved q_table during training: 49900\n",
            "Training finished.\n",
            "[[  0.           0.           0.           0.           0.\n",
            "    0.        ]\n",
            " [ -1.24999956  -1.24999782  -1.24999956  -1.24999782  -1.24998912\n",
            "  -10.24999782]\n",
            " [ -1.249728    -1.24864     -1.249728    -1.24864     -1.2432\n",
            "  -10.24864   ]\n",
            " ...\n",
            " [ -1.2432      -1.216       -1.2432      -1.24864    -10.2432\n",
            "  -10.2432    ]\n",
            " [ -1.24998912  -1.2499456   -1.24998912  -1.2499456  -10.24998912\n",
            "  -10.24998912]\n",
            " [ -0.4         -1.08        -0.4          3.          -9.4\n",
            "   -9.4       ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyMZPw9F9FwW"
      },
      "source": [
        "** There are four designated locations in the grid world indicated by R(ed), B(lue), G(reen), and Y(ellow). When the episode starts, the taxi starts off at a random square and the passenger is at a random location. The taxi drive to the passenger's location, pick up the passenger, drive to the passenger's destination (another one of the four specified locations), and then drop off the passenger. Once the passenger is dropped off, the episode ends. There are 500 discrete states since there are 25 taxi positions, 5 possible locations of the passenger (including the case when the passenger is the taxi), and 4 destination locations. Actions: There are 6 discrete deterministic actions: **\n",
        "\n",
        "    0: move south\n",
        "    1: move north\n",
        "    2: move east\n",
        "    3: move west\n",
        "    4: pickup passenger\n",
        "    5: dropoff passenger\n",
        "Rewards: There is a reward of -1 for each action and an additional reward of +20 for delievering the passenger. There is a reward of -10 for executing actions \"pickup\" and \"dropoff\" illegally. Rendering:\n",
        "\n",
        "    blue: passenger\n",
        "    magenta: destination\n",
        "    yellow: empty taxi\n",
        "    green: full taxi\n",
        "    other letters: locations\n",
        "\n",
        "\n",
        "state space is represented by:\n",
        "    (taxi_row, taxi_col, passenger_location, destination)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Gi7AXtkCmFM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "532c0889-77f1-43c6-eb58-62fe488e686f"
      },
      "source": [
        "# At state 499 i will definitely move west\n",
        "state = 499\n",
        "print(training_memory[0][state])\n",
        "print(training_memory[20][state])\n",
        "print(training_memory[50][state])\n",
        "print(training_memory[200][state])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1.008    -1.177806 -0.91      1.05     -7.       -7.      ]\n",
            "[-0.5824     -1.08079223 -0.40415428  3.         -9.38056    -9.39998632]\n",
            "[-0.40001197 -1.08       -0.40000002  3.         -9.39999872 -9.4       ]\n",
            "[-0.4  -1.08 -0.4   3.   -9.4  -9.4 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ptaEXB2DVhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1736087b-57aa-494d-de68-c0772b7f92ee"
      },
      "source": [
        "# At state 77 i will definitely move east\n",
        "state = 77\n",
        "print(training_memory[0][state])\n",
        "print(training_memory[20][state])\n",
        "print(training_memory[50][state])\n",
        "print(training_memory[200][state])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1.03049441 -1.15752    -0.91       -1.008      -7.         -9.198     ]\n",
            "[-1.07999991 -0.40001495  3.         -1.08004012 -9.39998897 -9.40001281]\n",
            "[-1.08 -0.4   3.   -1.08 -9.4  -9.4 ]\n",
            "[-1.08 -0.4   3.   -1.08 -9.4  -9.4 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDYTOt1BEnom"
      },
      "source": [
        "# To show that at state 393, how the move evolved\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "def printmd(string):\n",
        "    display(Markdown(string))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dwwIlFp67Dg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "82f61902-2ad1-47ea-9b53-0177137938e4"
      },
      "source": [
        "action_dict = {0:  \"move south\"\n",
        ",1: \"move north\"\n",
        ",2: \"move east\"\n",
        ",3: \"move west\"\n",
        ",4: \"pickup passenger\"\n",
        ",5: \"dropoff passenger\"\n",
        "}\n",
        "\n",
        "ENV_STATE = env.reset()\n",
        "print(env.render(mode='ansi'))\n",
        "state_memory = [i[ENV_STATE] for i in training_memory]\n",
        "printmd(\"For state **{}**\".format(ENV_STATE))\n",
        "for step, i in enumerate(state_memory):\n",
        "    \n",
        "    if step % 20==0:\n",
        "        choice = np.argmax(i)\n",
        "        printmd(\"for episode in {}, q table action is {} and it will ... **{}**\".format(step*100, choice, action_dict[choice]))\n",
        "        print(i)\n",
        "        print()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|\u001b[35mR\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "|\u001b[43m \u001b[0m| : | : |\n",
            "|Y| : |\u001b[34;1mB\u001b[0m: |\n",
            "+---------+\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "For state **312**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 0, q table action is 0 and it will ... **move south**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.2499597   -1.24998883  -1.24996969  -1.24998244 -10.24909704\n",
            " -10.24175059]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 2000, q table action is 1 and it will ... **move north**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.25        -1.25        -1.25        -1.25       -10.24999216\n",
            " -10.24925745]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 4000, q table action is 1 and it will ... **move north**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.25        -1.25        -1.25        -1.25       -10.24999929\n",
            " -10.24997995]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 6000, q table action is 1 and it will ... **move north**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.25        -1.25        -1.25        -1.25       -10.24999929\n",
            " -10.24999946]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 8000, q table action is 1 and it will ... **move north**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.25        -1.25        -1.25        -1.25       -10.24999998\n",
            " -10.25      ]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 10000, q table action is 1 and it will ... **move north**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.25        -1.25        -1.25        -1.25       -10.24999998\n",
            " -10.25      ]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 12000, q table action is 1 and it will ... **move north**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.25        -1.25        -1.25        -1.25       -10.24999999\n",
            " -10.25      ]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 14000, q table action is 1 and it will ... **move north**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.25  -1.25  -1.25  -1.25 -10.25 -10.25]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 16000, q table action is 1 and it will ... **move north**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.25  -1.25  -1.25  -1.25 -10.25 -10.25]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 18000, q table action is 1 and it will ... **move north**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.25  -1.25  -1.25  -1.25 -10.25 -10.25]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 20000, q table action is 1 and it will ... **move north**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.25  -1.25  -1.25  -1.25 -10.25 -10.25]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 22000, q table action is 1 and it will ... **move north**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.25  -1.25  -1.25  -1.25 -10.25 -10.25]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 24000, q table action is 1 and it will ... **move north**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.25  -1.25  -1.25  -1.25 -10.25 -10.25]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 26000, q table action is 1 and it will ... **move north**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.25  -1.25  -1.25  -1.25 -10.25 -10.25]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 28000, q table action is 1 and it will ... **move north**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.25  -1.25  -1.25  -1.25 -10.25 -10.25]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 30000, q table action is 1 and it will ... **move north**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.25  -1.25  -1.25  -1.25 -10.25 -10.25]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 32000, q table action is 1 and it will ... **move north**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.25  -1.25  -1.25  -1.25 -10.25 -10.25]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 34000, q table action is 1 and it will ... **move north**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.25  -1.25  -1.25  -1.25 -10.25 -10.25]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 36000, q table action is 1 and it will ... **move north**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.25  -1.25  -1.25  -1.25 -10.25 -10.25]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 38000, q table action is 1 and it will ... **move north**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.25  -1.25  -1.25  -1.25 -10.25 -10.25]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 40000, q table action is 1 and it will ... **move north**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.25  -1.25  -1.25  -1.25 -10.25 -10.25]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 42000, q table action is 1 and it will ... **move north**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.25  -1.25  -1.25  -1.25 -10.25 -10.25]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 44000, q table action is 1 and it will ... **move north**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.25  -1.25  -1.25  -1.25 -10.25 -10.25]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 46000, q table action is 1 and it will ... **move north**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.25  -1.25  -1.25  -1.25 -10.25 -10.25]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 48000, q table action is 1 and it will ... **move north**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.25  -1.25  -1.25  -1.25 -10.25 -10.25]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZWqI-fz4ZnI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e6142a2-7b73-4355-9d60-678ed116017d"
      },
      "source": [
        "# Testing............\n",
        "\n",
        "import time\n",
        "def print_frames(frames):\n",
        "    for i, frame in enumerate(frames):\n",
        "        clear_output(wait=True)\n",
        "        print(frame['frame'])\n",
        "        print(f\"Episode: {frame['episode']}\")\n",
        "        print(f\"Timestep: {i + 1}\")\n",
        "        print(f\"State: {frame['state']}\")\n",
        "        print(f\"Action: {frame['action']}\")\n",
        "        print(f\"Reward: {frame['reward']}\")\n",
        "        time.sleep(0.8)\n",
        "\n",
        "total_epochs, total_penalties = 0, 0\n",
        "episodes = 10 # Try 10 rounds\n",
        "frames = []\n",
        "\n",
        "for ep in range(episodes):\n",
        "    state = env.reset()\n",
        "    epochs, penalties, reward = 0, 0, 0\n",
        "    \n",
        "    done = False\n",
        "    \n",
        "    while not done:\n",
        "        action = np.argmax(q_table[state]) # deterministic (exploit), not stochastic (explore), only explore in training\n",
        "        env\n",
        "        state, reward, done, info = env.step(action) #gym\n",
        "\n",
        "        if reward == -10:\n",
        "            penalties += 1\n",
        "        \n",
        "        # Put each rendered frame into dict for animation, gym generated\n",
        "        frames.append({\n",
        "            'frame': env.render(mode='ansi'),\n",
        "            'episode': ep, \n",
        "            'state': state,\n",
        "            'action': action,\n",
        "            'reward': reward\n",
        "            }\n",
        "        )\n",
        "        epochs += 1\n",
        "\n",
        "    total_penalties += penalties\n",
        "    total_epochs += epochs\n",
        "\n",
        "print_frames(frames)\n",
        "\n",
        "print(f\"Results after {episodes} episodes:\")\n",
        "print(f\"Average timesteps per episode: {total_epochs / episodes}\")\n",
        "print(f\"Average penalties per episode: {total_penalties / episodes}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|\u001b[35m\u001b[34;1m\u001b[43mR\u001b[0m\u001b[0m\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "  (Dropoff)\n",
            "\n",
            "Episode: 7\n",
            "Timestep: 98\n",
            "State: 0\n",
            "Action: 5\n",
            "Reward: 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaD6awL34hp4"
      },
      "source": [
        ""
      ]
    }
  ]
}
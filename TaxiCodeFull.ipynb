{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TaxiCodeFull.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SWys5jC4iEO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a27a97b6-65c6-4153-dfeb-e73432f08bbe"
      },
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import random\n",
        "from IPython.display import clear_output\n",
        "from IPython.display import Markdown, display\n",
        "def printmd(string):\n",
        "    display(Markdown(string))\n",
        "\n",
        "# https://towardsdatascience.com/reinforcement-learning-with-python-8ef0242a2fa2\n",
        "# Init Taxi-V2 Env\n",
        "env = gym.make(\"Taxi-v3\").env\n",
        "\n",
        "# Init arbitary values\n",
        "q_table = np.zeros([env.observation_space.n, env.action_space.n])\n",
        "\n",
        "# Hyperparameters\n",
        "alpha = 0.7 # Momemtum 0.2, Current 0.8 Greedy, 0.2 is to reduce volatality and flip flop\n",
        "gamma = 0.2 # Learning Rate 0.1 Greedyness is 10%\n",
        "epsilon = 0.1 # explore 10% exploit 90%\n",
        "\n",
        "\n",
        "all_epochs = []\n",
        "all_penalties = []\n",
        "training_memory = []\n",
        "\n",
        "for i in range(1, 50000):\n",
        "    state = env.reset()\n",
        "\n",
        "    # Init Vars\n",
        "    epochs, penalties, reward, = 0, 0, 0\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        if random.uniform(0, 1) < epsilon:\n",
        "            # Check the action space\n",
        "            action = env.action_space.sample()\n",
        "        else:\n",
        "            # Check the learned values\n",
        "            action = np.argmax(q_table[state])\n",
        "\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "\n",
        "        old_value = q_table[state, action]\n",
        "        next_max = np.max(q_table[next_state])\n",
        "\n",
        "        # Update the new value\n",
        "        new_value = (1 - alpha) * old_value + alpha * \\\n",
        "            (reward + gamma * next_max)\n",
        "        q_table[state, action] = new_value        \n",
        "        \n",
        "        if reward == -10:\n",
        "            penalties += 1\n",
        "\n",
        "        state = next_state\n",
        "        epochs += 1\n",
        "    \n",
        "\n",
        "    if i % 100 == 0:\n",
        "        training_memory.append(q_table.copy())\n",
        "        clear_output(wait=True)\n",
        "        print(\"Episode:\", i)\n",
        "        print(\"Saved q_table during training:\", i)\n",
        "\n",
        "print(\"Training finished.\")\n",
        "print(q_table)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode: 49900\n",
            "Saved q_table during training: 49900\n",
            "Training finished.\n",
            "[[  0.           0.           0.           0.           0.\n",
            "    0.        ]\n",
            " [ -1.24999956  -1.24999782  -1.24999956  -1.24999782  -1.24998912\n",
            "  -10.24999782]\n",
            " [ -1.249728    -1.24864     -1.249728    -1.24864     -1.2432\n",
            "  -10.24864   ]\n",
            " ...\n",
            " [ -1.24266508  -1.216       -1.24251888  -1.24818805  -7.\n",
            "  -10.21665611]\n",
            " [ -1.24997104  -1.2499456   -1.24998367  -1.2499456   -7.\n",
            "  -10.2420912 ]\n",
            " [ -0.40037179  -1.0584      -0.5824       3.          -9.3352\n",
            "   -9.39997766]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyMZPw9F9FwW"
      },
      "source": [
        "** There are four designated locations in the grid world indicated by R(ed), B(lue), G(reen), and Y(ellow). When the episode starts, the taxi starts off at a random square and the passenger is at a random location. The taxi drive to the passenger's location, pick up the passenger, drive to the passenger's destination (another one of the four specified locations), and then drop off the passenger. Once the passenger is dropped off, the episode ends. There are 500 discrete states since there are 25 taxi positions, 5 possible locations of the passenger (including the case when the passenger is the taxi), and 4 destination locations. Actions: There are 6 discrete deterministic actions: **\n",
        "\n",
        "    0: move south\n",
        "    1: move north\n",
        "    2: move east\n",
        "    3: move west\n",
        "    4: pickup passenger\n",
        "    5: dropoff passenger\n",
        "Rewards: There is a reward of -1 for each action and an additional reward of +20 for delievering the passenger. There is a reward of -10 for executing actions \"pickup\" and \"dropoff\" illegally. Rendering:\n",
        "\n",
        "    blue: passenger\n",
        "    magenta: destination\n",
        "    yellow: empty taxi\n",
        "    green: full taxi\n",
        "    other letters: locations\n",
        "\n",
        "\n",
        "state space is represented by:\n",
        "    (taxi_row, taxi_col, passenger_location, destination)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Gi7AXtkCmFM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "124603e8-dcd6-4cf3-e268-46503d5a879d"
      },
      "source": [
        "# At state 499 i will definitely move west\n",
        "state = 499\n",
        "print(training_memory[0][state])\n",
        "print(training_memory[20][state])\n",
        "print(training_memory[50][state])\n",
        "print(training_memory[200][state])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.196      -0.19       -0.196       0.69808456 -1.         -1.        ]\n",
            "[-0.196      -0.19       -0.196       6.56515184 -1.         -1.85811493]\n",
            "[-0.196      -0.19       -0.196      10.08690409 -1.         -1.85811493]\n",
            "[ 0.36812688  0.28922308 -0.196      10.99948509 -1.47548993 -1.85811493]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ptaEXB2DVhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8c62985-5554-416f-e057-ec1b448cd35b"
      },
      "source": [
        "# At state 77 i will definitely move east\n",
        "state = 77\n",
        "print(training_memory[0][state])\n",
        "print(training_memory[20][state])\n",
        "print(training_memory[50][state])\n",
        "print(training_memory[200][state])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.20176    -0.19        1.56090623 -0.20176    -1.         -1.        ]\n",
            "[-0.20176    -0.19        8.78744551 -0.3025382  -1.         -1.66257716]\n",
            "[-0.20176    -0.19       10.66790744 -0.3025382  -1.         -1.93309658]\n",
            "[-0.20176     0.38844581 10.99951661 -0.35312314 -1.2561397  -2.08054712]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDYTOt1BEnom"
      },
      "source": [
        "from IPython.display import Markdown, display\n",
        "def printmd(string):\n",
        "    display(Markdown(string))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dwwIlFp67Dg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9bc15ba9-3193-4e89-fe7f-4df3c64abaf7"
      },
      "source": [
        "action_dict = {0:  \"move south\"\n",
        ",1: \"move north\"\n",
        ",2: \"move east\"\n",
        ",3: \"move west\"\n",
        ",4: \"pickup passenger\"\n",
        ",5: \"dropoff passenger\"\n",
        "}\n",
        "\n",
        "ENV_STATE = env.reset()\n",
        "print(env.render(mode='ansi'))\n",
        "state_memory = [i[ENV_STATE] for i in training_memory]\n",
        "printmd(\"For state **{}**\".format(ENV_STATE))\n",
        "for step, i in enumerate(state_memory):\n",
        "    \n",
        "    if step % 20==0:\n",
        "        choice = np.argmax(i)\n",
        "        printmd(\"for episode in {}, q table action is {} and it will ... **{}**\".format(step*100, choice, action_dict[choice]))\n",
        "        print(i)\n",
        "        print()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|\u001b[35mR\u001b[0m: | : :\u001b[43mG\u001b[0m|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |\u001b[34;1mB\u001b[0m: |\n",
            "+---------+\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "For state **92**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 0, q table action is 0 and it will ... **move south**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[-1.24970578 -1.24974593 -1.24985543 -1.24981037 -6.         -6.        ]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 2000, q table action is 3 and it will ... **move west**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[-1.24999997 -1.24999997 -1.24999997 -1.24999997 -8.54999999 -8.54999571]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 4000, q table action is 3 and it will ... **move west**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[-1.24999998 -1.24999999 -1.24999998 -1.24999998 -8.54999999 -9.56999828]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 6000, q table action is 3 and it will ... **move west**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[-1.24999998 -1.24999999 -1.24999998 -1.24999998 -8.54999999 -9.56999828]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 8000, q table action is 0 and it will ... **move south**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[-1.24999998 -1.24999999 -1.24999998 -1.24999998 -8.54999999 -9.97799931]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 10000, q table action is 0 and it will ... **move south**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[-1.24999998 -1.24999999 -1.24999998 -1.24999998 -8.54999999 -9.97799931]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 12000, q table action is 3 and it will ... **move west**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.24999998  -1.24999999  -1.24999998  -1.24999998  -8.54999999\n",
            " -10.14119972]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 14000, q table action is 0 and it will ... **move south**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.24999998  -1.24999999  -1.24999998  -1.24999998  -8.54999999\n",
            " -10.14119972]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 16000, q table action is 0 and it will ... **move south**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.24999998  -1.24999999  -1.24999998  -1.24999998  -8.54999999\n",
            " -10.14119972]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 18000, q table action is 0 and it will ... **move south**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.24999998  -1.24999999  -1.24999998  -1.24999998  -8.54999999\n",
            " -10.14119972]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 20000, q table action is 0 and it will ... **move south**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.24999998  -1.24999999  -1.24999998  -1.24999998  -9.56999999\n",
            " -10.14119972]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 22000, q table action is 0 and it will ... **move south**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.24999998  -1.24999999  -1.24999998  -1.24999998  -9.56999999\n",
            " -10.14119972]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 24000, q table action is 0 and it will ... **move south**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.24999998  -1.24999999  -1.24999998  -1.24999998  -9.56999999\n",
            " -10.14119972]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 26000, q table action is 0 and it will ... **move south**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.24999998  -1.24999999  -1.24999998  -1.24999998  -9.56999999\n",
            " -10.14119972]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 28000, q table action is 0 and it will ... **move south**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.24999998  -1.24999999  -1.24999998  -1.24999998  -9.56999999\n",
            " -10.14119972]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 30000, q table action is 0 and it will ... **move south**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.24999998  -1.24999999  -1.24999998  -1.24999998  -9.56999999\n",
            " -10.14119972]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 32000, q table action is 0 and it will ... **move south**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.24999998  -1.24999999  -1.24999998  -1.24999998  -9.978\n",
            " -10.14119972]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 34000, q table action is 0 and it will ... **move south**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.24999998  -1.24999999  -1.24999998  -1.24999998  -9.978\n",
            " -10.14119972]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 36000, q table action is 0 and it will ... **move south**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.24999998  -1.24999999  -1.24999998  -1.24999998  -9.978\n",
            " -10.14119972]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 38000, q table action is 0 and it will ... **move south**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.24999998  -1.24999999  -1.24999998  -1.24999998  -9.978\n",
            " -10.14119972]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 40000, q table action is 0 and it will ... **move south**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.24999998  -1.24999999  -1.24999998  -1.24999998  -9.978\n",
            " -10.14119972]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 42000, q table action is 0 and it will ... **move south**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.24999998  -1.24999999  -1.24999998  -1.24999998  -9.978\n",
            " -10.14119972]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 44000, q table action is 0 and it will ... **move south**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.24999998  -1.24999999  -1.24999998  -1.24999998  -9.978\n",
            " -10.14119972]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 46000, q table action is 0 and it will ... **move south**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.24999998  -1.24999999  -1.24999998  -1.24999998  -9.978\n",
            " -10.14119972]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "for episode in 48000, q table action is 0 and it will ... **move south**",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[ -1.24999998  -1.24999999  -1.24999999  -1.24999998 -10.1412\n",
            " -10.14119972]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZWqI-fz4ZnI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0498965-9d20-48fe-81c2-5fe4c9d683ca"
      },
      "source": [
        "import time\n",
        "def print_frames(frames):\n",
        "    for i, frame in enumerate(frames):\n",
        "        clear_output(wait=True)\n",
        "        print(frame['frame'])\n",
        "        print(f\"Episode: {frame['episode']}\")\n",
        "        print(f\"Timestep: {i + 1}\")\n",
        "        print(f\"State: {frame['state']}\")\n",
        "        print(f\"Action: {frame['action']}\")\n",
        "        print(f\"Reward: {frame['reward']}\")\n",
        "        time.sleep(0.8)\n",
        "\n",
        "total_epochs, total_penalties = 0, 0\n",
        "episodes = 10\n",
        "frames = []\n",
        "\n",
        "for ep in range(episodes):\n",
        "    state = env.reset()\n",
        "    epochs, penalties, reward = 0, 0, 0\n",
        "    \n",
        "    done = False\n",
        "    \n",
        "    while not done:\n",
        "        action = np.argmax(q_table[state])\n",
        "        env\n",
        "        state, reward, done, info = env.step(action)\n",
        "\n",
        "        if reward == -10:\n",
        "            penalties += 1\n",
        "        \n",
        "        # Put each rendered frame into dict for animation\n",
        "        frames.append({\n",
        "            'frame': env.render(mode='ansi'),\n",
        "            'episode': ep, \n",
        "            'state': state,\n",
        "            'action': action,\n",
        "            'reward': reward\n",
        "            }\n",
        "        )\n",
        "        epochs += 1\n",
        "\n",
        "    total_penalties += penalties\n",
        "    total_epochs += epochs\n",
        "\n",
        "print_frames(frames)\n",
        "\n",
        "print(f\"Results after {episodes} episodes:\")\n",
        "print(f\"Average timesteps per episode: {total_epochs / episodes}\")\n",
        "print(f\"Average penalties per episode: {total_penalties / episodes}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|\u001b[35m\u001b[34;1m\u001b[43mR\u001b[0m\u001b[0m\u001b[0m: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|Y| : |B: |\n",
            "+---------+\n",
            "  (Dropoff)\n",
            "\n",
            "Episode: 9\n",
            "Timestep: 132\n",
            "State: 0\n",
            "Action: 5\n",
            "Reward: 20\n",
            "Results after 10 episodes:\n",
            "Average timesteps per episode: 13.2\n",
            "Average penalties per episode: 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaD6awL34hp4"
      },
      "source": [
        ""
      ]
    }
  ]
}